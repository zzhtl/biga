use candle_core::{Device, Tensor};
use candle_nn::{Module, Optimizer, VarMap, AdamW};
use serde::{Deserialize, Serialize};
use std::path::PathBuf;
use uuid::Uuid;
use std::fs;
use std::time::{SystemTime, UNIX_EPOCH};
use rand;
use chrono::{self, Weekday, Datelike};
use sqlx::Row;


// ç®€åŒ–çš„æ¨¡å‹é…ç½®ç»“æ„ä½“
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelConfig {
    pub model_type: String,
    pub input_size: usize,
    pub hidden_size: usize,
    pub output_size: usize,
    pub dropout: f64,
    pub learning_rate: f64,
    pub n_layers: usize,
    pub n_heads: usize,
    pub max_seq_len: usize,
}

// ç®€åŒ–çš„æ¨¡å‹åˆ›å»ºå‡½æ•°
fn create_model(config: &ModelConfig, device: &Device) -> Result<(VarMap, Box<dyn Module + Send + Sync>), candle_core::Error> {
    // åˆ›å»ºä¸€ä¸ªç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹
    let varmap = VarMap::new();
    
    // å®šä¹‰æ­£ç¡®çš„è¾“å…¥å’Œè¾“å‡ºå½¢çŠ¶
    let input_size = config.input_size;
    let output_size = config.output_size;
    
    struct LinearRegression {
        linear: candle_nn::Linear,
    }
    
    impl LinearRegression {
        fn new(in_size: usize, out_size: usize, vb: candle_nn::VarBuilder) -> Result<Self, candle_core::Error> {
            let linear = candle_nn::linear(in_size, out_size, vb)?;
            Ok(Self { linear })
        }
    }
    
    unsafe impl Send for LinearRegression {}
    unsafe impl Sync for LinearRegression {}
    
    impl Module for LinearRegression {
        fn forward(&self, xs: &Tensor) -> Result<Tensor, candle_core::Error> {
            self.linear.forward(xs)
        }
    }
    
    let vb = candle_nn::VarBuilder::from_varmap(&varmap, candle_core::DType::F32, device);
    let model = LinearRegression::new(input_size, output_size, vb)?;
    
    let model: Box<dyn Module + Send + Sync> = Box::new(model);
    
    Ok((varmap, model))
}

// ç®€åŒ–çš„æ¨¡å‹ä¿å­˜å‡½æ•°
fn save_model(varmap: &VarMap, path: &std::path::Path) -> Result<(), candle_core::Error> {
    varmap.save(path)?;
    Ok(())
}

// æ•°æ®åº“è·¯å¾„æŸ¥æ‰¾å‡½æ•°
fn find_database_path() -> Option<PathBuf> {
    let current_dir = std::env::current_dir().ok()?;
    
    // å°è¯•å¤šä¸ªå¯èƒ½çš„æ•°æ®åº“è·¯å¾„
    let possible_paths = [
        current_dir.join("db/stock_data.db"),
        current_dir.join("src-tauri/db/stock_data.db"),
        current_dir.parent()?.join("src-tauri/db/stock_data.db"), // å¦‚æœåœ¨ src-tauri ç›®å½•å†…è¿è¡Œ
    ];
    
    for path in &possible_paths {
        println!("æ£€æŸ¥æ•°æ®åº“è·¯å¾„: {}", path.display());
        if path.exists() {
            println!("âœ… æ‰¾åˆ°æ•°æ®åº“æ–‡ä»¶: {}", path.display());
            return Some(path.clone());
        }
    }
    
    println!("âŒ æœªæ‰¾åˆ°æ•°æ®åº“æ–‡ä»¶");
    None
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelInfo {
    pub id: String,
    pub name: String, 
    pub stock_code: String,
    pub created_at: u64,
    pub model_type: String,
    pub features: Vec<String>,
    pub target: String,
    pub prediction_days: usize,
    pub accuracy: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Prediction {
    pub target_date: String,
    pub predicted_price: f64,
    pub predicted_change_percent: f64,
    pub confidence: f64,
    pub trading_signal: Option<String>,
    pub signal_strength: Option<f64>,
    pub technical_indicators: Option<TechnicalIndicatorValues>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TechnicalIndicatorValues {
    pub rsi: f64,
    pub macd_histogram: f64,
    pub kdj_j: f64,
    pub cci: f64,
    pub obv_trend: f64, // OBVç›¸å¯¹äºå‡å€¼çš„æ¯”ä¾‹
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrainingRequest {
    pub stock_code: String,
    pub model_name: String,
    pub start_date: String,
    pub end_date: String,
    pub features: Vec<String>,
    pub target: String,
    pub prediction_days: usize,
    pub model_type: String,
    pub epochs: usize,
    pub batch_size: usize,
    pub learning_rate: f64,
    pub dropout: f64,
    pub train_test_split: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PredictionRequest {
    pub stock_code: String,
    pub model_name: Option<String>,
    pub prediction_days: usize,
    pub use_candle: bool,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct TrainingResult {
    pub metadata: ModelInfo,
    pub accuracy: f64,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct EvaluationResult {
    pub accuracy: f64,
    pub confusion_matrix: Vec<Vec<usize>>,
    pub precision: f64,
    pub recall: f64,
    pub f1_score: f64,
    pub prediction_examples: Vec<PredictionExample>,
}

#[derive(Debug, Serialize, Deserialize)]
pub struct PredictionExample {
    pub actual: f64,
    pub predicted: f64,
    pub features: Vec<f64>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TrainingLog {
    pub epoch: usize,
    pub loss: f64,
    pub timestamp: String,
    pub message: Option<String>,
}



// å®šä¹‰è·å–æ¨¡å‹ä¿å­˜ç›®å½•çš„å‡½æ•°
fn get_models_dir() -> PathBuf {
    let app_dir = dirs::data_dir().unwrap_or_else(|| PathBuf::from("./data"));
    let models_dir = app_dir.join("biga/models");
    fs::create_dir_all(&models_dir).unwrap_or_default();
    models_dir
}

// å®šä¹‰è·å–ç‰¹å®šæ¨¡å‹ç›®å½•çš„å‡½æ•°
fn get_model_dir(model_id: &str) -> PathBuf {
    get_models_dir().join(model_id)
}

// ä¿å­˜æ¨¡å‹å…ƒæ•°æ®
fn save_model_metadata(metadata: &ModelInfo) -> std::io::Result<()> {
    let model_dir = get_model_dir(&metadata.id);
    fs::create_dir_all(&model_dir)?;
    
    let metadata_path = model_dir.join("metadata.json");
    let metadata_json = serde_json::to_string_pretty(metadata)?;
    fs::write(metadata_path, metadata_json)?;
    
    Ok(())
}

// è¯»å–æ¨¡å‹å…ƒæ•°æ®
fn load_model_metadata(model_id: &str) -> std::io::Result<ModelInfo> {
    let metadata_path = get_model_dir(model_id).join("metadata.json");
    let metadata_json = fs::read_to_string(metadata_path)?;
    let metadata: ModelInfo = serde_json::from_str(&metadata_json)?;
    Ok(metadata)
}

// åˆ—å‡ºç‰¹å®šè‚¡ç¥¨ä»£ç çš„æ‰€æœ‰æ¨¡å‹
pub fn list_models(symbol: &str) -> Vec<ModelInfo> {
    let models_dir = get_models_dir();
    
    let mut models = Vec::new();
    
    if let Ok(entries) = fs::read_dir(models_dir) {
        for entry in entries.flatten() {
            let path = entry.path();
            
            if path.is_dir() {
                let metadata_path = path.join("metadata.json");
                
                if metadata_path.exists() {
                    if let Ok(metadata_json) = fs::read_to_string(metadata_path) {
                        if let Ok(metadata) = serde_json::from_str::<ModelInfo>(&metadata_json) {
                            if metadata.stock_code == symbol {
                                models.push(metadata);
                            }
                        }
                    }
                }
            }
        }
    }
    
    // æŒ‰åˆ›å»ºæ—¶é—´é™åºæ’åº
    models.sort_by(|a, b| b.created_at.cmp(&a.created_at));
    models
}

// åˆ é™¤æ¨¡å‹
pub fn delete_model(model_id: &str) -> std::io::Result<()> {
    let model_dir = get_model_dir(model_id);
    fs::remove_dir_all(model_dir)?;
    Ok(())
}

// æ”¹è¿›çš„æ•°æ®é¢„å¤„ç†å‡½æ•°
async fn prepare_stock_data(
    request: &TrainingRequest,
) -> std::result::Result<(Tensor, Tensor, Tensor, Tensor, Vec<String>), candle_core::Error> {
    // è®¾ç½®è®¾å¤‡
    let device = Device::Cpu;
    
    let symbol = &request.stock_code;
    
    // è§£æå‰ç«¯ä¼ æ¥çš„æ—¥æœŸèŒƒå›´
    let end_date = chrono::Local::now().naive_local().date();
    let user_start_date = chrono::NaiveDate::parse_from_str(&request.start_date, "%Y-%m-%d")
        .unwrap_or_else(|_| end_date - chrono::Duration::days(210)); // é»˜è®¤210å¤©
    let user_end_date = chrono::NaiveDate::parse_from_str(&request.end_date, "%Y-%m-%d")
        .unwrap_or(end_date);
    
    // è®¡ç®—ç”¨æˆ·è¯·æ±‚çš„å¤©æ•°èŒƒå›´
    let requested_days = (user_end_date - user_start_date).num_days();
    
    // ä¸ºAè‚¡èŠ‚å‡æ—¥å¢åŠ é¢å¤–ç¼“å†²æœŸ
    // å¦‚æœç”¨æˆ·å·²ç»åŒ…å«äº†ç¼“å†²æœŸï¼ˆå¦‚180+30=210å¤©ï¼‰ï¼Œæˆ‘ä»¬å†å¢åŠ ä¸€äº›ä»¥ç¡®ä¿æ•°æ®å……è¶³
    let additional_buffer = if requested_days >= 200 { 
        60  // ç”¨æˆ·å·²æœ‰ç¼“å†²ï¼Œå†åŠ 60å¤©
    } else { 
        90  // ç”¨æˆ·æ²¡æœ‰ç¼“å†²ï¼ŒåŠ 90å¤©
    };
    
    let extended_start_date = user_start_date - chrono::Duration::days(additional_buffer);
    
    // ç¡®ä¿ä¸ä¼šæŸ¥è¯¢è¿‡äºä¹…è¿œçš„æ•°æ®ï¼ˆæœ€å¤š2å¹´ï¼‰
    let max_start_date = end_date - chrono::Duration::days(730);
    let actual_start_date = if extended_start_date < max_start_date {
        max_start_date
    } else {
        extended_start_date
    };
    
    let start_date_str = actual_start_date.format("%Y-%m-%d").to_string();
    let end_date_str = user_end_date.format("%Y-%m-%d").to_string();
    
    println!("ğŸ“… Aè‚¡æ•°æ®è·å–ç­–ç•¥:");
    println!("   ç”¨æˆ·è¯·æ±‚èŒƒå›´: {} åˆ° {} ({} å¤©)", 
             user_start_date.format("%Y-%m-%d"), 
             user_end_date.format("%Y-%m-%d"), 
             requested_days);
    println!("   å®é™…æŸ¥è¯¢èŒƒå›´: {} åˆ° {} ({} å¤©ï¼Œå«èŠ‚å‡æ—¥ç¼“å†²)", 
             start_date_str, end_date_str, 
             (user_end_date - actual_start_date).num_days());
    
    // ä½¿ç”¨sqlxæŸ¥è¯¢æ•°æ®åº“è·å–å†å²æ•°æ®
    let historical_data = match get_historical_data_from_db(symbol, &start_date_str, &end_date_str).await {
        Ok(data) => data,
        Err(e) => {
            eprintln!("ä»æ•°æ®åº“è·å–æ•°æ®å¤±è´¥: {}", e);
            return Err(candle_core::Error::Msg(format!("è·å–å†å²æ•°æ®å¤±è´¥: {}", e)));
        }
    };
    
    if historical_data.is_empty() {
        return Err(candle_core::Error::Msg("å†å²æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹".to_string()));
    }
    
    println!("âœ… è·å–åˆ°{}æ¡å†å²æ•°æ®", historical_data.len());
    
    // æ•°æ®è´¨é‡æ£€æŸ¥ - é’ˆå¯¹Aè‚¡ç‰¹ç‚¹ä¼˜åŒ–
    let valid_data: Vec<_> = historical_data.into_iter()
        .filter(|data| {
            // Aè‚¡åŸºæœ¬æ•°æ®éªŒè¯
            data.close > 0.0 && data.volume >= 0 && 
            data.open > 0.0 && data.high > 0.0 && data.low > 0.0 &&
            data.high >= data.low && data.high >= data.open && 
            data.high >= data.close && data.low <= data.open && data.low <= data.close &&
            // Aè‚¡æ¶¨è·Œå¹…é™åˆ¶æ£€æŸ¥ï¼ˆSTè‚¡ç¥¨20%ï¼Œæ™®é€šè‚¡ç¥¨10%ï¼‰
            data.change_percent.abs() <= 25.0 && // å…è®¸ä¸€äº›æ•°æ®è¯¯å·®
            // æˆäº¤é‡åˆç†æ€§æ£€æŸ¥
            data.volume < 1_000_000_000_000 // é¿å…å¼‚å¸¸å¤§çš„æˆäº¤é‡
        })
        .collect();
    
    println!("âœ… è¿‡æ»¤åæœ‰æ•ˆæ•°æ®{}æ¡", valid_data.len());
    
    // Aè‚¡äº¤æ˜“æ—¥æ•°é‡ä¼°ç®—ï¼šä¸€å¹´çº¦250ä¸ªäº¤æ˜“æ—¥
    let min_required_days = 120; // æœ€å°‘çº¦åŠå¹´äº¤æ˜“æ•°æ®
    let recommended_days = 180; // æ¨èçº¦9ä¸ªæœˆäº¤æ˜“æ•°æ®
    let optimal_days = 250; // æœ€ä½³çº¦1å¹´äº¤æ˜“æ•°æ®
    
    if valid_data.len() < min_required_days {
        return Err(candle_core::Error::Msg(format!(
            "Aè‚¡æœ‰æ•ˆäº¤æ˜“æ•°æ®ä¸è¶³ï¼Œå½“å‰{}å¤©ï¼Œéœ€è¦è‡³å°‘{}å¤©æ•°æ®ï¼ˆçº¦åŠå¹´äº¤æ˜“æ—¥ï¼‰", 
            valid_data.len(), min_required_days
        )));
    }
    
    if valid_data.len() < recommended_days {
        println!("âš ï¸  è­¦å‘Š: å½“å‰æ•°æ®é‡{}å¤©å°‘äºæ¨èçš„{}å¤©ï¼Œå¯èƒ½å½±å“æ¨¡å‹å‡†ç¡®ç‡", 
                 valid_data.len(), recommended_days);
    } else if valid_data.len() >= optimal_days {
        println!("âœ… æ•°æ®é‡å……è¶³: {}å¤© >= {}å¤©ï¼Œæœ‰åˆ©äºæé«˜æ¨¡å‹å‡†ç¡®ç‡", 
                 valid_data.len(), optimal_days);
    }
    
    // æ„å»ºç‰¹å¾å’Œæ ‡ç­¾
    let mut dates = Vec::new();
    let mut prices = Vec::new();
    let mut volumes = Vec::new();
    let mut highs = Vec::new();
    let mut lows = Vec::new();
    let mut opens = Vec::new();
    let mut features_matrix = Vec::new();
    
    // æŒ‰æ—¥æœŸæ’åºï¼ˆä»æ—§åˆ°æ–°ï¼‰
    let mut sorted_data = valid_data.clone();
    sorted_data.sort_by(|a, b| a.date.cmp(&b.date));
    
    // é¦–å…ˆæå–åŸºç¡€æ•°æ®
    for data in &sorted_data {
        dates.push(data.date.clone());
        prices.push(data.close);
        volumes.push(data.volume);
        highs.push(data.high);
        lows.push(data.low);
        opens.push(data.open);
    }
    
    // æ•°æ®å¹³æ»‘å¤„ç†ï¼šç§»é™¤å¼‚å¸¸å€¼
    let prices = smooth_price_data(&prices);
    let volumes = smooth_volume_data(&volumes);
    
    // ä¸ºæ¯å¤©å‡†å¤‡ä¸€ä¸ªç‰¹å¾å‘é‡ï¼ˆåŠ¨æ€è®¡ç®—æ‰€éœ€çš„å†å²çª—å£ï¼‰
    let required_days = request.features.iter()
        .map(|f| get_feature_required_days(f))
        .max()
        .unwrap_or(20);
    
    // ä½¿ç”¨è¾ƒå°çš„lookback_windowï¼Œä½†ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—æ‰€æœ‰ç‰¹å¾
    let lookback_window = required_days.max(30).min(prices.len() / 2);
    
    println!("ğŸ“Š ç‰¹å¾è®¡ç®—çª—å£: {}å¤©, æ€»ä»·æ ¼æ•°æ®: {}å¤©", lookback_window, prices.len());
    
    for i in lookback_window..prices.len() {
        let mut feature_vector = Vec::new();
        
        // æå–è¯·æ±‚ä¸­æŒ‡å®šçš„ç‰¹å¾
        for feature_name in &request.features {
            let feature_value = calculate_feature_value(
                feature_name, 
                &prices, 
                &volumes, 
                i, 
                lookback_window,
                Some(&highs),
                Some(&lows)
            )?;
            feature_vector.push(feature_value);
        }
        
        features_matrix.push(feature_vector);
    }
    
    println!("ğŸ”¢ ç”Ÿæˆç‰¹å¾çŸ©é˜µ: {}è¡Œ x {}åˆ—", features_matrix.len(), 
             if features_matrix.is_empty() { 0 } else { features_matrix[0].len() });
    
    // ç§»é™¤å‰é¢çš„æ•°æ®ï¼Œå› ä¸ºæ²¡æœ‰è®¡ç®—ç‰¹å¾
    dates = dates[lookback_window..].to_vec();
    let valid_prices = prices[lookback_window..].to_vec();
    
    // åˆ›å»ºç›®æ ‡å˜é‡: ä½¿ç”¨æœªæ¥nå¤©çš„ä»·æ ¼å˜åŒ–ç‡
    let pred_days = request.prediction_days;
    let mut targets = Vec::new();
    
    // é˜²æ­¢æ•´æ•°æº¢å‡ºï¼šç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œé¢„æµ‹
    if features_matrix.len() <= pred_days {
        return Err(candle_core::Error::Msg(format!(
            "æ•°æ®ä¸è¶³ä»¥è¿›è¡Œ{}å¤©é¢„æµ‹ï¼Œå½“å‰ç‰¹å¾æ•°æ®{}å¤©ï¼Œéœ€è¦è‡³å°‘{}å¤©", 
            pred_days, features_matrix.len(), pred_days + 1
        )));
    }
    
    for i in 0..(features_matrix.len() - pred_days) {
        let current_price = valid_prices[i];
        
        // è®¡ç®—æœªæ¥å‡ å¤©çš„å¹³å‡ä»·æ ¼ï¼Œå‡å°‘å™ªéŸ³
        let future_prices: Vec<f64> = (1..=pred_days)
            .map(|day| valid_prices.get(i + day).copied().unwrap_or(current_price))
            .collect();
        
        let future_avg_price = future_prices.iter().sum::<f64>() / future_prices.len() as f64;
        let change_rate = (future_avg_price - current_price) / current_price;
        
        // é™åˆ¶å˜åŒ–ç‡èŒƒå›´ï¼Œé¿å…æç«¯å€¼å½±å“è®­ç»ƒ
        let clamped_change_rate = change_rate.clamp(-0.5, 0.5);
        targets.push(clamped_change_rate);
    }
    
    // æˆªæ–­ç‰¹å¾çŸ©é˜µï¼Œä½¿å…¶ä¸ç›®æ ‡å˜é‡é•¿åº¦åŒ¹é…
    features_matrix.truncate(targets.len());
    dates.truncate(targets.len());
    
    // ç‰¹å¾æ ‡å‡†åŒ–
    let (normalized_features, _feature_stats) = normalize_features(&features_matrix)?;
    
    // åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† - ä½¿ç”¨æ—¶é—´åºåˆ—åˆ’åˆ†
    let train_size = (targets.len() as f64 * request.train_test_split) as usize;
    
    // è½¬æ¢ä¸ºå¼ é‡
    let features_len = normalized_features[0].len();
    let x_train_vec: Vec<f64> = normalized_features[0..train_size].iter()
        .flat_map(|v| v.iter().copied())
        .collect();
    
    let y_train_vec: Vec<f64> = targets[0..train_size].to_vec();
    
    let x_test_vec: Vec<f64> = normalized_features[train_size..].iter()
        .flat_map(|v| v.iter().copied())
        .collect();
    
    let y_test_vec: Vec<f64> = targets[train_size..].to_vec();
    
    // åˆ›å»ºå¼ é‡ï¼Œä½¿ç”¨F32ç±»å‹ä»¥åŒ¹é…æ¨¡å‹æƒé‡
    let x_train_f32: Vec<f32> = x_train_vec.iter().map(|&x| x as f32).collect();
    let y_train_f32: Vec<f32> = y_train_vec.iter().map(|&y| y as f32).collect();
    let x_test_f32: Vec<f32> = x_test_vec.iter().map(|&x| x as f32).collect();
    let y_test_f32: Vec<f32> = y_test_vec.iter().map(|&y| y as f32).collect();
    
    let x_train = Tensor::from_slice(&x_train_f32, &[train_size, features_len], &device)?;
    let y_train = Tensor::from_slice(&y_train_f32, &[train_size, 1], &device)?;
    
    let test_size = targets.len() - train_size;
    let x_test = Tensor::from_slice(&x_test_f32, &[test_size, features_len], &device)?;
    let y_test = Tensor::from_slice(&y_test_f32, &[test_size, 1], &device)?;
    
    println!("æ•°æ®é¢„å¤„ç†å®Œæˆ: è®­ç»ƒé›†{}æ ·æœ¬, æµ‹è¯•é›†{}æ ·æœ¬, ç‰¹å¾ç»´åº¦{}", 
             train_size, test_size, features_len);
    
    Ok((x_train, y_train, x_test, y_test, dates))
}

// æ•°æ®å¹³æ»‘å¤„ç†å‡½æ•°
fn smooth_price_data(prices: &[f64]) -> Vec<f64> {
    let mut smoothed = prices.to_vec();
    
    // ä½¿ç”¨ä¸­ä½æ•°æ»¤æ³¢å™¨ç§»é™¤ä»·æ ¼å¼‚å¸¸å€¼
    for i in 2..smoothed.len()-2 {
        let window: Vec<f64> = smoothed[i-2..=i+2].to_vec();
        let mut sorted_window = window.clone();
        sorted_window.sort_by(|a, b| a.partial_cmp(b).unwrap());
        let median = sorted_window[2];
        
        // å¦‚æœå½“å‰å€¼ä¸ä¸­ä½æ•°ç›¸å·®è¶…è¿‡20%ï¼Œç”¨ä¸­ä½æ•°æ›¿æ¢
        if (smoothed[i] - median).abs() / median > 0.2 {
            smoothed[i] = median;
        }
    }
    
    smoothed
}

fn smooth_volume_data(volumes: &[i64]) -> Vec<i64> {
    let mut smoothed = volumes.to_vec();
    
    // ç§»é™¤æˆäº¤é‡å¼‚å¸¸å€¼
    for i in 2..smoothed.len()-2 {
        let window: Vec<i64> = smoothed[i-2..=i+2].to_vec();
        let avg = window.iter().sum::<i64>() as f64 / window.len() as f64;
        
        // å¦‚æœå½“å‰å€¼ä¸å¹³å‡å€¼ç›¸å·®è¶…è¿‡5å€ï¼Œç”¨å¹³å‡å€¼æ›¿æ¢
        if (smoothed[i] as f64 - avg).abs() / avg > 5.0 {
            smoothed[i] = avg as i64;
        }
    }
    
    smoothed
}

// è·å–ç‰¹å¾æ‰€éœ€çš„å†å²å¤©æ•°
fn get_feature_required_days(feature_name: &str) -> usize {
    match feature_name {
        "close" | "volume" | "change_percent" => 1,
        "ma5" => 5,
        "ma10" => 10,
        "ma20" | "bollinger" | "cci" => 20,
        "rsi" | "stochastic_k" | "stochastic_d" | "dmi_plus" | "dmi_minus" | "adx" => 14,
        "macd" | "macd_dif" | "macd_dea" | "macd_histogram" => 26,
        "momentum" => 10,
        "kdj_k" | "kdj_d" | "kdj_j" => 9,
        "obv" => 2,
        _ => 1,
    }
}

// è®¡ç®—å•ä¸ªç‰¹å¾å€¼
fn calculate_feature_value(
    feature_name: &str,
    prices: &[f64],
    volumes: &[i64],
    index: usize,
    _lookback_window: usize,
    highs: Option<&[f64]>,
    lows: Option<&[f64]>,
) -> Result<f64, candle_core::Error> {
    match feature_name {
        "close" => {
            Ok(prices[index])
        },
        "volume" => {
            Ok(volumes[index] as f64)
        },
        "change_percent" => {
            if index > 0 {
                let prev_price = prices[index - 1];
                let change = (prices[index] - prev_price) / prev_price;
                Ok(change)
            } else {
                Ok(0.0)
            }
        },
        "ma5" => {
            if index >= 4 {
                let ma5 = prices[index-4..=index].iter().sum::<f64>() / 5.0;
                Ok(ma5)
            } else {
                Ok(prices[index])
            }
        },
        "ma10" => {
            if index >= 9 {
                let ma10 = prices[index-9..=index].iter().sum::<f64>() / 10.0;
                Ok(ma10)
            } else {
                Ok(prices[index])
            }
        },
        "ma20" => {
            if index >= 19 {
                let ma20 = prices[index-19..=index].iter().sum::<f64>() / 20.0;
                Ok(ma20)
            } else {
                Ok(prices[index])
            }
        },
        "rsi" => {
            if index >= 14 {
                Ok(calculate_rsi(&prices[index-14..=index]))
            } else { 
                Ok(50.0) // é»˜è®¤ä¸­æ€§RSI
            }
        },
        "macd" => {
            if index >= 25 {
                Ok(calculate_macd(&prices[index-25..=index]))
            } else {
                Ok(0.0)
            }
        },
        "bollinger" => {
            if index >= 19 {
                Ok(calculate_bollinger_position(&prices[index-19..=index], prices[index]))
            } else {
                Ok(0.0)
            }
        },
        "stochastic_k" => {
            if index >= 13 {
                Ok(calculate_stochastic_k(&prices[index-13..=index], prices[index]))
            } else {
                Ok(0.5)
            }
        },
        "stochastic_d" => {
            if index >= 15 {
                // è®¡ç®—å‰3å¤©çš„Kå€¼çš„å¹³å‡å€¼
                let k_values: Vec<f64> = (0..3)
                    .map(|i| {
                        let k_index = index - i;
                        if k_index >= 13 {
                            calculate_stochastic_k(&prices[k_index-13..=k_index], prices[k_index])
                        } else {
                            0.5
                        }
                    })
                    .collect();
                Ok(k_values.iter().sum::<f64>() / k_values.len() as f64)
            } else {
                Ok(0.5)
            }
        },
        "momentum" => {
            if index >= 10 {
                let momentum = prices[index] / prices[index-10] - 1.0;
                Ok(momentum)
            } else {
                Ok(0.0)
            }
        },
        "kdj_k" | "kdj_d" | "kdj_j" => {
            // KDJæŒ‡æ ‡
            if let (Some(highs), Some(lows)) = (highs, lows) {
                if index >= 9 && highs.len() > index && lows.len() > index {
                    let start = index.saturating_sub(8);
                    let (k, d, j) = calculate_kdj(&highs[start..=index], &lows[start..=index], &prices[start..=index], 9);
                    match feature_name {
                        "kdj_k" => Ok(k / 100.0), // å½’ä¸€åŒ–åˆ°0-1
                        "kdj_d" => Ok(d / 100.0),
                        "kdj_j" => Ok(j / 100.0),
                        _ => Ok(0.0)
                    }
                } else {
                    Ok(0.5) // é»˜è®¤ä¸­æ€§å€¼
                }
            } else {
                Ok(0.5)
            }
        },
        "cci" => {
            // CCIæŒ‡æ ‡
            if let (Some(highs), Some(lows)) = (highs, lows) {
                if index >= 20 && highs.len() > index && lows.len() > index {
                    let start = index.saturating_sub(19);
                    let cci = calculate_cci(&highs[start..=index], &lows[start..=index], &prices[start..=index], 20);
                    Ok(cci / 200.0) // å½’ä¸€åŒ–ï¼ŒCCIé€šå¸¸åœ¨-200åˆ°200ä¹‹é—´
                } else {
                    Ok(0.0)
                }
            } else {
                Ok(0.0)
            }
        },
        "obv" => {
            // OBVæŒ‡æ ‡
            if index >= 1 {
                let obv = calculate_obv(&prices[0..=index], &volumes[0..=index]);
                // å½’ä¸€åŒ–OBVï¼ˆç›¸å¯¹äºå¹³å‡æˆäº¤é‡ï¼‰
                let avg_volume = volumes[0..=index].iter().sum::<i64>() as f64 / (index + 1) as f64;
                Ok(obv / (avg_volume * (index + 1) as f64))
            } else {
                Ok(0.0)
            }
        },
        "macd_dif" | "macd_dea" | "macd_histogram" => {
            // å®Œæ•´MACDæŒ‡æ ‡
            if index >= 26 {
                let (dif, dea, histogram) = calculate_macd_full(&prices[0..=index]);
                let normalized = match feature_name {
                    "macd_dif" => dif / prices[index],
                    "macd_dea" => dea / prices[index],
                    "macd_histogram" => histogram / prices[index],
                    _ => 0.0
                };
                Ok(normalized)
            } else {
                Ok(0.0)
            }
        },
        "dmi_plus" | "dmi_minus" | "adx" => {
            // DMIæŒ‡æ ‡
            if let (Some(highs), Some(lows)) = (highs, lows) {
                if index >= 14 && highs.len() > index && lows.len() > index {
                    let start = index.saturating_sub(13);
                    let (di_plus, di_minus, adx, _) = calculate_dmi(&highs[start..=index], &lows[start..=index], &prices[start..=index], 14);
                    match feature_name {
                        "dmi_plus" => Ok(di_plus / 100.0),
                        "dmi_minus" => Ok(di_minus / 100.0),
                        "adx" => Ok(adx / 100.0),
                        _ => Ok(0.0)
                    }
                } else {
                    Ok(0.0)
                }
            } else {
                Ok(0.0)
            }
        },
        _ => {
            Ok(0.0)
        }
    }
}

// ç‰¹å¾æ ‡å‡†åŒ–
fn normalize_features(features: &[Vec<f64>]) -> Result<(Vec<Vec<f64>>, Vec<(f64, f64)>), candle_core::Error> {
    if features.is_empty() {
        return Ok((Vec::new(), Vec::new()));
    }
    
    let feature_count = features[0].len();
    let mut stats = Vec::with_capacity(feature_count);
    let mut normalized = vec![vec![0.0; feature_count]; features.len()];
    
    // è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å‡å€¼å’Œæ ‡å‡†å·®
    for feature_idx in 0..feature_count {
        let values: Vec<f64> = features.iter().map(|row| row[feature_idx]).collect();
        let mean = values.iter().sum::<f64>() / values.len() as f64;
        let variance = values.iter()
            .map(|v| (v - mean).powi(2))
            .sum::<f64>() / values.len() as f64;
        let std_dev = variance.sqrt().max(1e-8); // é¿å…é™¤é›¶
        
        stats.push((mean, std_dev));
        
        // æ ‡å‡†åŒ–è¯¥ç‰¹å¾
        for (row_idx, row) in features.iter().enumerate() {
            normalized[row_idx][feature_idx] = (row[feature_idx] - mean) / std_dev;
        }
    }
    
    Ok((normalized, stats))
}

// RSIè®¡ç®—å‡½æ•°
fn calculate_rsi(prices: &[f64]) -> f64 {
    if prices.len() < 2 {
        return 50.0;
    }
    
    let mut gains = 0.0;
    let mut losses = 0.0;
    
    for i in 1..prices.len() {
        let change = prices[i] - prices[i-1];
        if change > 0.0 {
            gains += change;
        } else {
            losses += -change;
        }
    }
    
    gains /= (prices.len() - 1) as f64;
    losses /= (prices.len() - 1) as f64;
    
    if losses == 0.0 {
        100.0
    } else {
        100.0 - (100.0 / (1.0 + (gains / losses)))
    }
}

// MACDè®¡ç®—å‡½æ•°
fn calculate_macd(prices: &[f64]) -> f64 {
    if prices.len() < 26 {
        return 0.0;
    }
    
    let ema12 = calculate_ema(prices, 12);
    let ema26 = calculate_ema(prices, 26);
    ema12 - ema26
}

// å¸ƒæ—å¸¦ä½ç½®è®¡ç®—
fn calculate_bollinger_position(prices: &[f64], current_price: f64) -> f64 {
    if prices.len() < 20 {
        return 0.0;
    }
    
    let ma = prices.iter().sum::<f64>() / prices.len() as f64;
    let variance = prices.iter()
        .map(|p| (p - ma).powi(2))
        .sum::<f64>() / prices.len() as f64;
    let std_dev = variance.sqrt();
    
    let upper_band = ma + 2.0 * std_dev;
    let lower_band = ma - 2.0 * std_dev;
    
    if upper_band == lower_band {
        0.0
    } else {
        (current_price - lower_band) / (upper_band - lower_band) - 0.5
    }
}

// éšæœºæŒ‡æ ‡Kå€¼è®¡ç®—
fn calculate_stochastic_k(prices: &[f64], current_price: f64) -> f64 {
    if prices.is_empty() {
        return 0.5;
    }
    
    let highest = prices.iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));
    let lowest = prices.iter().fold(f64::INFINITY, |a, &b| a.min(b));
    
    if highest == lowest {
        0.5
    } else {
        (current_price - lowest) / (highest - lowest)
    }
}

// ä»æ•°æ®åº“è·å–å†å²æ•°æ®
async fn get_historical_data_from_db(symbol: &str, start_date: &str, end_date: &str) -> Result<Vec<HistoricalDataType>, String> {
    // åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„æ•°æ®åº“è¿æ¥
    use sqlx::sqlite::SqlitePoolOptions;
    
    // ä½¿ç”¨åŠ¨æ€æ•°æ®åº“è·¯å¾„æŸ¥æ‰¾
    let db_path = find_database_path()
        .ok_or_else(|| "æ‰¾ä¸åˆ°æ•°æ®åº“æ–‡ä»¶".to_string())?;
    
    let connection_string = format!("sqlite://{}", db_path.display());
    let pool = SqlitePoolOptions::new()
        .max_connections(1)
        .connect(&connection_string)
        .await
        .map_err(|e| format!("è¿æ¥æ•°æ®åº“å¤±è´¥: {}", e))?;
    
    let records = sqlx::query_as::<_, HistoricalDataType>(
        r#"SELECT * FROM historical_data 
           WHERE symbol = ? AND date BETWEEN ? AND ?
           ORDER BY date ASC"#
    )
    .bind(symbol)
    .bind(start_date)
    .bind(end_date)
    .fetch_all(&pool)
    .await
    .map_err(|e| format!("æŸ¥è¯¢å†å²æ•°æ®å¤±è´¥: {}", e))?;
    
    Ok(records)
}

// å†å²æ•°æ®ç»“æ„ä½“
#[derive(Debug, Clone)]
struct HistoricalDataType {
    pub date: String,
    pub open: f64,
    pub close: f64,
    pub high: f64,
    pub low: f64,
    pub volume: i64,
    pub change_percent: f64,
}

// å®ç°FromRowç‰¹å¾ï¼Œä½¿å…¶å¯ä»¥ä»æ•°æ®åº“è¡Œè½¬æ¢
impl<'r> sqlx::FromRow<'r, sqlx::sqlite::SqliteRow> for HistoricalDataType {
    fn from_row(row: &'r sqlx::sqlite::SqliteRow) -> Result<Self, sqlx::Error> {
        Ok(Self {
            date: row.try_get("date")?,
            open: row.try_get("open")?,
            close: row.try_get("close")?,
            high: row.try_get("high")?,
            low: row.try_get("low")?,
            volume: row.try_get("volume")?,
            change_percent: row.try_get("change_percent")?,
        })
    }
}

// è®¡ç®—æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿
fn calculate_ema(data: &[f64], period: usize) -> f64 {
    if data.is_empty() || period == 0 || data.len() < period {
        return 0.0;
    }
    
    let multiplier = 2.0 / (period as f64 + 1.0);
    let mut ema = data[0];
    
    for i in 1..data.len() {
        ema = (data[i] - ema) * multiplier + ema;
    }
    
    ema
}

// ğŸ¯ æ–°å¢ï¼šè®¡ç®—å®Œæ•´çš„MACDæŒ‡æ ‡ï¼ˆåŒ…æ‹¬DIFã€DEAã€MACDæŸ±ï¼‰
fn calculate_macd_full(prices: &[f64]) -> (f64, f64, f64) {
    if prices.len() < 26 {
        return (0.0, 0.0, 0.0);
    }
    
    // è®¡ç®—EMA12å’ŒEMA26
    let ema12 = calculate_ema(prices, 12);
    let ema26 = calculate_ema(prices, 26);
    
    // DIF = EMA12 - EMA26
    let dif = ema12 - ema26;
    
    // è®¡ç®—æœ€è¿‘9å¤©çš„DIFå€¼ç”¨äºè®¡ç®—DEA
    let mut dif_values = Vec::new();
    for i in (prices.len().saturating_sub(9))..prices.len() {
        if i >= 26 {
            let sub_prices = &prices[0..=i];
            let sub_ema12 = calculate_ema(sub_prices, 12);
            let sub_ema26 = calculate_ema(sub_prices, 26);
            dif_values.push(sub_ema12 - sub_ema26);
        }
    }
    
    // DEA = EMA(DIF, 9)
    let dea = if dif_values.len() >= 9 {
        calculate_ema(&dif_values, 9)
    } else {
        dif // å¦‚æœæ•°æ®ä¸è¶³ï¼Œä½¿ç”¨DIFä½œä¸ºDEA
    };
    
    // MACDæŸ± = 2 * (DIF - DEA)
    let macd = 2.0 * (dif - dea);
    
    (dif, dea, macd)
}

// ğŸ¯ æ–°å¢ï¼šè®¡ç®—KDJæŒ‡æ ‡
fn calculate_kdj(highs: &[f64], lows: &[f64], closes: &[f64], n: usize) -> (f64, f64, f64) {
    if highs.len() < n || lows.len() < n || closes.len() < n {
        return (50.0, 50.0, 50.0);
    }
    
    let len = highs.len();
    let start = len.saturating_sub(n);
    
    // è®¡ç®—Næ—¥å†…æœ€é«˜ä»·å’Œæœ€ä½ä»·
    let highest = highs[start..].iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));
    let lowest = lows[start..].iter().fold(f64::INFINITY, |a, &b| a.min(b));
    
    if highest == lowest {
        return (50.0, 50.0, 50.0);
    }
    
    // è®¡ç®—RSV
    let rsv = (closes[len - 1] - lowest) / (highest - lowest) * 100.0;
    
    // ç®€åŒ–è®¡ç®—ï¼šä½¿ç”¨æœ€è¿‘3å¤©çš„å¹³å‡å€¼æ¨¡æ‹ŸKå€¼çš„å¹³æ»‘
    let mut k_values = vec![rsv];
    for i in 1..3 {
        if len > i {
            let idx = len - 1 - i;
            if idx >= start {
                let h = highs[start..=idx].iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));
                let l = lows[start..=idx].iter().fold(f64::INFINITY, |a, &b| a.min(b));
                if h > l {
                    k_values.push((closes[idx] - l) / (h - l) * 100.0);
                }
            }
        }
    }
    
    let k = k_values.iter().sum::<f64>() / k_values.len() as f64;
    
    // Då€¼æ˜¯Kå€¼çš„3æ—¥ç§»åŠ¨å¹³å‡
    let d = k * 0.667 + 50.0 * 0.333; // ç®€åŒ–è®¡ç®—
    
    // J = 3K - 2D
    let j = 3.0 * k - 2.0 * d;
    
    (k, d, j)
}

// ğŸ¯ æ–°å¢ï¼šè®¡ç®—OBVï¼ˆèƒ½é‡æ½®ï¼‰æŒ‡æ ‡
fn calculate_obv(prices: &[f64], volumes: &[i64]) -> f64 {
    if prices.len() < 2 || volumes.len() < 2 {
        return 0.0;
    }
    
    let mut obv = 0.0;
    for i in 1..prices.len().min(volumes.len()) {
        if prices[i] > prices[i - 1] {
            obv += volumes[i] as f64;
        } else if prices[i] < prices[i - 1] {
            obv -= volumes[i] as f64;
        }
        // ä»·æ ¼ä¸å˜æ—¶ï¼ŒOBVä¿æŒä¸å˜
    }
    
    obv
}

// ğŸ¯ æ–°å¢ï¼šè®¡ç®—CCIï¼ˆå•†å“é€šé“æŒ‡æ•°ï¼‰
fn calculate_cci(highs: &[f64], lows: &[f64], closes: &[f64], period: usize) -> f64 {
    if highs.len() < period || lows.len() < period || closes.len() < period {
        return 0.0;
    }
    
    let start = highs.len().saturating_sub(period);
    let mut tp_values = Vec::new(); // Typical Price
    
    for i in start..highs.len() {
        let tp = (highs[i] + lows[i] + closes[i]) / 3.0;
        tp_values.push(tp);
    }
    
    // è®¡ç®—ç§»åŠ¨å¹³å‡
    let ma = tp_values.iter().sum::<f64>() / tp_values.len() as f64;
    
    // è®¡ç®—å¹³å‡åå·®
    let md = tp_values.iter()
        .map(|&tp| (tp - ma).abs())
        .sum::<f64>() / tp_values.len() as f64;
    
    if md == 0.0 {
        return 0.0;
    }
    
    // CCI = (TP - MA) / (0.015 * MD)
    let current_tp = (highs.last().unwrap() + lows.last().unwrap() + closes.last().unwrap()) / 3.0;
    (current_tp - ma) / (0.015 * md)
}

// ğŸ¯ æ–°å¢ï¼šè®¡ç®—DMIï¼ˆåŠ¨å‘æŒ‡æ ‡ï¼‰
fn calculate_dmi(highs: &[f64], lows: &[f64], closes: &[f64], period: usize) -> (f64, f64, f64, f64) {
    if highs.len() < period + 1 || lows.len() < period + 1 || closes.len() < period + 1 {
        return (0.0, 0.0, 0.0, 0.0);
    }
    
    let mut tr_values = Vec::new();
    let mut dm_plus_values = Vec::new();
    let mut dm_minus_values = Vec::new();
    
    // è®¡ç®—TRã€+DMã€-DM
    for i in 1..highs.len() {
        // True Range
        let h_l = highs[i] - lows[i];
        let h_pc = (highs[i] - closes[i - 1]).abs();
        let l_pc = (lows[i] - closes[i - 1]).abs();
        let tr = h_l.max(h_pc).max(l_pc);
        tr_values.push(tr);
        
        // Directional Movement
        let up_move = highs[i] - highs[i - 1];
        let down_move = lows[i - 1] - lows[i];
        
        let dm_plus = if up_move > down_move && up_move > 0.0 { up_move } else { 0.0 };
        let dm_minus = if down_move > up_move && down_move > 0.0 { down_move } else { 0.0 };
        
        dm_plus_values.push(dm_plus);
        dm_minus_values.push(dm_minus);
    }
    
    if tr_values.len() < period {
        return (0.0, 0.0, 0.0, 0.0);
    }
    
    // è®¡ç®—å¹³æ»‘åçš„å€¼ï¼ˆä½¿ç”¨ç®€å•ç§»åŠ¨å¹³å‡ä»£æ›¿Wilder'så¹³æ»‘ï¼‰
    let start = tr_values.len().saturating_sub(period);
    let atr = tr_values[start..].iter().sum::<f64>() / period as f64;
    let adm_plus = dm_plus_values[start..].iter().sum::<f64>() / period as f64;
    let adm_minus = dm_minus_values[start..].iter().sum::<f64>() / period as f64;
    
    if atr == 0.0 {
        return (0.0, 0.0, 0.0, 0.0);
    }
    
    // è®¡ç®—æ–¹å‘æŒ‡æ ‡
    let di_plus = (adm_plus / atr) * 100.0;
    let di_minus = (adm_minus / atr) * 100.0;
    
    // è®¡ç®—ADX
    let dx = if di_plus + di_minus == 0.0 {
        0.0
    } else {
        ((di_plus - di_minus).abs() / (di_plus + di_minus)) * 100.0
    };
    
    // ç®€åŒ–çš„ADXè®¡ç®—ï¼ˆåº”è¯¥æ˜¯DXçš„å¹³æ»‘å€¼ï¼‰
    let adx = dx;
    
    (di_plus, di_minus, adx, dx)
}

// ğŸ¯ æ–°å¢ï¼šè®¡ç®—SARï¼ˆæŠ›ç‰©çº¿åœæŸè½¬å‘ï¼‰æŒ‡æ ‡
fn calculate_sar(highs: &[f64], lows: &[f64], af_step: f64, af_max: f64) -> Vec<f64> {
    if highs.len() < 2 || lows.len() < 2 {
        return vec![0.0; highs.len()];
    }
    
    let mut sar_values = Vec::new();
    let mut is_uptrend = true;
    let mut af = af_step;
    let mut ep = highs[0]; // æå€¼ç‚¹
    let mut sar = lows[0];
    
    sar_values.push(sar);
    
    for i in 1..highs.len() {
        // è®¡ç®—æ–°çš„SAR
        let new_sar = sar + af * (ep - sar);
        
        if is_uptrend {
            // ä¸Šå‡è¶‹åŠ¿
            if lows[i] <= new_sar {
                // è¶‹åŠ¿åè½¬
                is_uptrend = false;
                sar = ep;
                ep = lows[i];
                af = af_step;
            } else {
                sar = new_sar;
                if highs[i] > ep {
                    ep = highs[i];
                    af = (af + af_step).min(af_max);
                }
            }
        } else {
            // ä¸‹é™è¶‹åŠ¿
            if highs[i] >= new_sar {
                // è¶‹åŠ¿åè½¬
                is_uptrend = true;
                sar = ep;
                ep = highs[i];
                af = af_step;
            } else {
                sar = new_sar;
                if lows[i] < ep {
                    ep = lows[i];
                    af = (af + af_step).min(af_max);
                }
            }
        }
        
        sar_values.push(sar);
    }
    
    sar_values
}

// ğŸ¯ æ–°å¢ï¼šç»¼åˆæŠ€æœ¯æŒ‡æ ‡åˆ†æå‡½æ•°
fn analyze_technical_signals(
    prices: &[f64], 
    highs: &[f64], 
    lows: &[f64], 
    volumes: &[i64]
) -> TechnicalSignals {
    let len = prices.len();
    
    // è®¡ç®—å„ç§æŠ€æœ¯æŒ‡æ ‡
    let (macd_dif, macd_dea, macd_histogram) = if len >= 26 {
        calculate_macd_full(prices)
    } else {
        (0.0, 0.0, 0.0)
    };
    
    let (kdj_k, kdj_d, kdj_j) = if len >= 14 && highs.len() >= 14 && lows.len() >= 14 {
        calculate_kdj(highs, lows, prices, 9)
    } else {
        (50.0, 50.0, 50.0)
    };
    
    let rsi = if len >= 14 {
        calculate_rsi(&prices[len.saturating_sub(14)..])
    } else {
        50.0
    };
    
    let cci = if len >= 20 && highs.len() >= 20 && lows.len() >= 20 {
        calculate_cci(highs, lows, prices, 20)
    } else {
        0.0
    };
    
    let obv = calculate_obv(prices, volumes);
    let obv_ma = if volumes.len() >= 10 {
        let recent_obv_values: Vec<f64> = (0..10).map(|i| {
            let end = volumes.len() - i;
            calculate_obv(&prices[0..end], &volumes[0..end])
        }).collect();
        recent_obv_values.iter().sum::<f64>() / recent_obv_values.len() as f64
    } else {
        obv
    };
    
         // ğŸ¯ ç”Ÿæˆä¹°å–ä¿¡å·
    let mut buy_signals = 0;
    let mut sell_signals = 0;
    let mut signal_strength: f64 = 0.0;
    
    // MACDä¿¡å·
    if macd_dif > macd_dea && macd_histogram > 0.0 {
        buy_signals += 1;
        signal_strength += 0.15;
    } else if macd_dif < macd_dea && macd_histogram < 0.0 {
        sell_signals += 1;
        signal_strength -= 0.15;
    }
    
    // KDJä¿¡å·
    if kdj_j < 20.0 || (kdj_k < 30.0 && kdj_d < 30.0) {
        buy_signals += 1;
        signal_strength += 0.2;
    } else if kdj_j > 80.0 || (kdj_k > 70.0 && kdj_d > 70.0) {
        sell_signals += 1;
        signal_strength -= 0.2;
    }
    
    // RSIä¿¡å·
    if rsi < 30.0 {
        buy_signals += 1;
        signal_strength += 0.15;
    } else if rsi > 70.0 {
        sell_signals += 1;
        signal_strength -= 0.15;
    }
    
    // CCIä¿¡å·
    if cci < -100.0 {
        buy_signals += 1;
        signal_strength += 0.1;
    } else if cci > 100.0 {
        sell_signals += 1;
        signal_strength -= 0.1;
    }
    
    // OBVä¿¡å·
    if obv > obv_ma {
        buy_signals += 1;
        signal_strength += 0.1;
    } else if obv < obv_ma {
        sell_signals += 1;
        signal_strength -= 0.1;
    }
    
    // ä»·æ ¼çªç ´ä¿¡å·
    if len >= 20 {
        let ma20 = prices[len-20..].iter().sum::<f64>() / 20.0;
        if prices[len-1] > ma20 * 1.02 {
            buy_signals += 1;
            signal_strength += 0.1;
        } else if prices[len-1] < ma20 * 0.98 {
            sell_signals += 1;
            signal_strength -= 0.1;
        }
    }
    
    // æˆäº¤é‡ä¿¡å·
    if volumes.len() >= 5 {
        let vol_ma5 = volumes[volumes.len()-5..].iter().sum::<i64>() as f64 / 5.0;
        let current_vol = *volumes.last().unwrap() as f64;
        if current_vol > vol_ma5 * 1.5 && prices[len-1] > prices[len-2] {
            buy_signals += 1;
            signal_strength += 0.1;
        }
    }
    
    // è®¡ç®—ç»¼åˆä¿¡å·
    let signal = if buy_signals > sell_signals + 2 {
        TradingSignal::StrongBuy
    } else if buy_signals > sell_signals {
        TradingSignal::Buy
    } else if sell_signals > buy_signals + 2 {
        TradingSignal::StrongSell
    } else if sell_signals > buy_signals {
        TradingSignal::Sell
    } else {
        TradingSignal::Hold
    };
    
    TechnicalSignals {
        macd_dif,
        macd_dea,
        macd_histogram,
        kdj_k,
        kdj_d,
        kdj_j,
        rsi,
        cci,
        obv,
        signal,
                 signal_strength: signal_strength.max(-1.0).min(1.0),
        buy_signals,
        sell_signals,
    }
}

// ğŸ¯ æ–°å¢ï¼šæŠ€æœ¯ä¿¡å·ç»“æ„ä½“
#[derive(Debug, Clone)]
struct TechnicalSignals {
    pub macd_dif: f64,
    pub macd_dea: f64,
    pub macd_histogram: f64,
    pub kdj_k: f64,
    pub kdj_d: f64,
    pub kdj_j: f64,
    pub rsi: f64,
    pub cci: f64,
    pub obv: f64,
    pub signal: TradingSignal,
    pub signal_strength: f64,
    pub buy_signals: i32,
    pub sell_signals: i32,
}

// ğŸ¯ æ–°å¢ï¼šäº¤æ˜“ä¿¡å·æšä¸¾
#[derive(Debug, Clone, PartialEq)]
enum TradingSignal {
    StrongBuy,
    Buy,
    Hold,
    Sell,
    StrongSell,
}

// è®­ç»ƒæ¨¡å‹å‡½æ•°
pub async fn train_candle_model(request: TrainingRequest) -> std::result::Result<TrainingResult, String> {
    let model_id = Uuid::new_v4().to_string();
    let model_type = request.model_type.clone();
    
    // å‡†å¤‡æ•°æ®
    let (x_train, y_train, x_test, y_test, _) = prepare_stock_data(&request).await
        .map_err(|e| format!("æ•°æ®å‡†å¤‡å¤±è´¥: {}", e))?;
    
    // è®¾ç½®è®¾å¤‡
    let device = Device::Cpu;
    
    // åˆ›å»ºæ¨¡å‹é…ç½®
    let config = ModelConfig {
        model_type: model_type.clone(),
        input_size: request.features.len(),
        hidden_size: 64, // éšè—å±‚å¤§å°
        output_size: 1,  // è¾“å‡ºå°ºå¯¸ (è‚¡ä»·)
        dropout: request.dropout,
        learning_rate: request.learning_rate,
        n_layers: 2,     // é»˜è®¤å€¼
        n_heads: 4,      // é»˜è®¤å€¼
        max_seq_len: 60, // é»˜è®¤å€¼
    };
    
    // åˆ›å»ºæ¨¡å‹
    let (varmap, model) = create_model(&config, &device)
        .map_err(|e| format!("æ¨¡å‹åˆ›å»ºå¤±è´¥: {}", e))?;
    
    // åˆ›å»ºä¼˜åŒ–å™¨
    let mut optimizer = AdamW::new_lr(varmap.all_vars(), request.learning_rate)
        .map_err(|e| format!("ä¼˜åŒ–å™¨åˆ›å»ºå¤±è´¥: {}", e))?;
    
    // è®­ç»ƒæ¨¡å‹
    let batch_size = request.batch_size;
    let num_batches = x_train.dim(0).unwrap() / batch_size;
    
    for epoch in 0..request.epochs {
        let mut epoch_loss = 0.0;
        
        for batch_idx in 0..num_batches {
            let batch_start = batch_idx * batch_size;
            let x_batch = x_train.narrow(0, batch_start, batch_size)
                .map_err(|e| format!("æ‰¹æ¬¡æ•°æ®å‡†å¤‡å¤±è´¥: {}", e))?;
            let y_batch = y_train.narrow(0, batch_start, batch_size)
                .map_err(|e| format!("æ‰¹æ¬¡æ•°æ®å‡†å¤‡å¤±è´¥: {}", e))?;
            
            // å‰å‘ä¼ æ’­
            let output = model.forward(&x_batch)
                .map_err(|e| format!("å‰å‘ä¼ æ’­å¤±è´¥: {}", e))?;
            
            // è®¡ç®—æŸå¤± (å‡æ–¹è¯¯å·®)
            // ç¡®ä¿è¾“å‡ºå’Œç›®æ ‡å¼ é‡çš„å½¢çŠ¶åŒ¹é…
            println!("è¾“å‡ºå½¢çŠ¶: {:?}, ç›®æ ‡å½¢çŠ¶: {:?}", output.dims(), y_batch.dims());
            
            // å¦‚æœè¾“å‡ºå½¢çŠ¶å’Œç›®æ ‡å½¢çŠ¶ä¸åŒ¹é…ï¼Œåˆ™è¿›è¡Œè°ƒæ•´
            let reshaped_output = if output.dims() != y_batch.dims() {
                if output.dim(0).unwrap() == y_batch.dim(0).unwrap() {
                    // å¦‚æœæ‰¹æ¬¡å¤§å°ç›¸åŒä½†è¾“å‡ºç»´åº¦ä¸åŒï¼Œå°è¯•reshape
                    output.reshape(&[output.dim(0).unwrap(), 1])
                        .map_err(|e| format!("è°ƒæ•´è¾“å‡ºå½¢çŠ¶å¤±è´¥: {}", e))?
                } else {
                    return Err(format!("è¾“å‡ºå½¢çŠ¶ {:?} å’Œç›®æ ‡å½¢çŠ¶ {:?} ä¸å…¼å®¹", output.dims(), y_batch.dims()));
                }
            } else {
                output
            };
            
            let loss = reshaped_output.sub(&y_batch).map_err(|e| format!("è®¡ç®—æŸå¤±å¤±è´¥: {}", e))?;
            let loss_squared = loss.sqr().map_err(|e| format!("è®¡ç®—å¹³æ–¹å¤±è´¥: {}", e))?;
            let loss = loss_squared.mean_all().map_err(|e| format!("è®¡ç®—å‡å€¼å¤±è´¥: {}", e))?;
            
            // åå‘ä¼ æ’­
            optimizer.backward_step(&loss)
                .map_err(|e| format!("åå‘ä¼ æ’­å¤±è´¥: {}", e))?;
            
            epoch_loss += loss.to_scalar::<f32>().unwrap() as f64;
        }
        
        // æ¯10ä¸ªepochè®°å½•ä¸€æ¬¡æŸå¤±
        if (epoch + 1) % 10 == 0 || epoch == 0 || epoch == request.epochs - 1 {
            println!("Epoch {}/{}, Loss: {:.4}", epoch + 1, request.epochs, epoch_loss / num_batches as f64);
        }
    }
    
    // è¯„ä¼°æ¨¡å‹
    let y_pred = model.forward(&x_test)
        .map_err(|e| format!("é¢„æµ‹å¤±è´¥: {}", e))?;
    
    // è½¬æ¢ä¸ºVecç”¨äºå‡†ç¡®ç‡è®¡ç®— - å¤„ç†ä¸åŒç»´åº¦çš„å¼ é‡
    let predictions_vec = match y_pred.dims() {
        // å¦‚æœæ˜¯1ç»´å¼ é‡ [n]
        [_] => {
            y_pred.to_vec1::<f32>().map_err(|e| format!("è½¬æ¢1ç»´é¢„æµ‹ç»“æœå¤±è´¥: {}", e))?
                .into_iter().map(|x| x as f64).collect::<Vec<f64>>()
        },
        // å¦‚æœæ˜¯2ç»´å¼ é‡ [n, 1] 
        [_, 1] => {
            y_pred.to_vec2::<f32>().map_err(|e| format!("è½¬æ¢2ç»´é¢„æµ‹ç»“æœå¤±è´¥: {}", e))?
                .into_iter().map(|row| row[0] as f64).collect::<Vec<f64>>()
        },
        // å¦‚æœæ˜¯å…¶ä»–2ç»´å¼ é‡ [n, m]
        [_, _] => {
            let vec2d = y_pred.to_vec2::<f32>().map_err(|e| format!("è½¬æ¢2ç»´é¢„æµ‹ç»“æœå¤±è´¥: {}", e))?;
            vec2d.into_iter().map(|row| row[0] as f64).collect::<Vec<f64>>() // å–ç¬¬ä¸€åˆ—
        },
        // å…¶ä»–ç»´åº¦
        _ => {
            return Err("é¢„æµ‹è¾“å‡ºå¼ é‡ç»´åº¦ä¸æ”¯æŒï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®".to_string());
        }
    };
    
    let actuals_vec = match y_test.dims() {
        // å¦‚æœæ˜¯1ç»´å¼ é‡ [n]
        [_] => {
            y_test.to_vec1::<f32>().map_err(|e| format!("è½¬æ¢1ç»´å®é™…ç»“æœå¤±è´¥: {}", e))?
                .into_iter().map(|x| x as f64).collect::<Vec<f64>>()
        },
        // å¦‚æœæ˜¯2ç»´å¼ é‡ [n, 1]
        [_, 1] => {
            y_test.to_vec2::<f32>().map_err(|e| format!("è½¬æ¢2ç»´å®é™…ç»“æœå¤±è´¥: {}", e))?
                .into_iter().map(|row| row[0] as f64).collect::<Vec<f64>>()
        },
        // å¦‚æœæ˜¯å…¶ä»–2ç»´å¼ é‡ [n, m]
        [_, _] => {
            let vec2d = y_test.to_vec2::<f32>().map_err(|e| format!("è½¬æ¢2ç»´å®é™…ç»“æœå¤±è´¥: {}", e))?;
            vec2d.into_iter().map(|row| row[0] as f64).collect::<Vec<f64>>() // å–ç¬¬ä¸€åˆ—
        },
        // å…¶ä»–ç»´åº¦
        _ => {
            return Err("å®é™…å€¼å¼ é‡ç»´åº¦ä¸æ”¯æŒï¼Œè¯·æ£€æŸ¥æ•°æ®å‡†å¤‡".to_string());
        }
    };
    
    // ä½¿ç”¨æ”¹è¿›çš„å‡†ç¡®ç‡è®¡ç®—æ–¹æ³•ï¼ˆæ›´é‡è§†æ–¹å‘é¢„æµ‹ï¼‰
    let (direction_accuracy, combined_accuracy) = calculate_direction_focused_accuracy(&predictions_vec, &actuals_vec);
    
    // è®¡ç®—MSEå’ŒRMSEç”¨äºæ—¥å¿—æ˜¾ç¤º
    let diff = y_pred.sub(&y_test).map_err(|e| format!("è®¡ç®—MSEå¤±è´¥: {}", e))?;
    let squared_diff = diff.sqr().map_err(|e| format!("è®¡ç®—å¹³æ–¹å¤±è´¥: {}", e))?;
    let mse = squared_diff.mean_all().map_err(|e| format!("è®¡ç®—å‡å€¼å¤±è´¥: {}", e))?;
    let mse = mse.to_scalar::<f32>().unwrap() as f64;
    let rmse = mse.sqrt();
    
    println!("è¯„ä¼°ç»“æœ: MSE = {:.4}, RMSE = {:.4}", mse, rmse);
    println!("ğŸ¯ æ–¹å‘é¢„æµ‹å‡†ç¡®ç‡: {:.2}% | ç»¼åˆå‡†ç¡®ç‡: {:.2}%", 
             direction_accuracy * 100.0, combined_accuracy * 100.0);
    println!("ğŸ“Š é¢„æµ‹å¼ é‡ç»´åº¦: {:?}, å®é™…å¼ é‡ç»´åº¦: {:?}", y_pred.dims(), y_test.dims());
    
    // ä¿å­˜æ¨¡å‹
    let model_dir = get_model_dir(&model_id);
    fs::create_dir_all(&model_dir).map_err(|e| format!("åˆ›å»ºæ¨¡å‹ç›®å½•å¤±è´¥: {}", e))?;
    
    let model_path = model_dir.join("model.safetensors");
    save_model(&varmap, &model_path).map_err(|e| format!("æ¨¡å‹ä¿å­˜å¤±è´¥: {}", e))?;
    
    // ä¿å­˜æ¨¡å‹å…ƒæ•°æ®
    let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
    
    let metadata = ModelInfo {
        id: model_id,
        name: request.model_name,
        stock_code: request.stock_code,
        created_at: now,
        model_type,
        features: request.features,
        target: request.target,
        prediction_days: request.prediction_days,
        accuracy: combined_accuracy,
    };
    
    save_model_metadata(&metadata).map_err(|e| format!("å…ƒæ•°æ®ä¿å­˜å¤±è´¥: {}", e))?;
    
    Ok(TrainingResult {
        metadata,
        accuracy: combined_accuracy,
    })
}

// è‚¡ç¥¨é¢„æµ‹å‡½æ•°
pub async fn predict_with_candle(request: PredictionRequest) -> std::result::Result<Vec<Prediction>, String> {
    let model_list = list_models(&request.stock_code);
    
    if model_list.is_empty() {
        return Err("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹".to_string());
    }
    
    // è·å–æ¨¡å‹å…ƒæ•°æ®
    let metadata = if let Some(model_name) = &request.model_name {
        model_list.iter()
            .find(|m| m.name == *model_name)
            .ok_or_else(|| format!("æ‰¾ä¸åˆ°åä¸º {} çš„æ¨¡å‹", model_name))?
            .clone()
    } else {
        // å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹åç§°ï¼Œä½¿ç”¨æœ€æ–°çš„æ¨¡å‹
        model_list[0].clone()
    };
    
    // åŠ è½½æ¨¡å‹
    let device = Device::Cpu;
    
    let config = ModelConfig {
        model_type: metadata.model_type.clone(),
        input_size: metadata.features.len(),
        hidden_size: 64,
        output_size: 1,
        dropout: 0.0, // é¢„æµ‹æ—¶ä¸ä½¿ç”¨dropout
        learning_rate: 0.001,
        n_layers: 2,   // é»˜è®¤å€¼
        n_heads: 4,    // é»˜è®¤å€¼
        max_seq_len: 60, // é»˜è®¤å€¼
    };
    
    let mut varmap = VarMap::new();
    
    let (_, model) = create_model(&config, &device)
        .map_err(|e| format!("æ¨¡å‹åˆ›å»ºå¤±è´¥: {}", e))?;
    
    let model_path = get_model_dir(&metadata.id).join("model.safetensors");
    varmap.load(&model_path).map_err(|e| format!("æ¨¡å‹åŠ è½½å¤±è´¥: {}", e))?;
    
    // è·å–æœ€è¿‘çš„çœŸå®å¸‚åœºæ•°æ®ç”¨äºé¢„æµ‹
    let (current_price, dates, prices, volumes, highs, lows) = get_recent_market_data(&request.stock_code, 60).await
        .map_err(|e| format!("è·å–å¸‚åœºæ•°æ®å¤±è´¥: {}", e))?;
    
    if prices.len() < 20 {
        return Err("å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹ï¼Œéœ€è¦è‡³å°‘20å¤©æ•°æ®".to_string());
    }
    
    // è®¡ç®—ç‰¹å¾å‘é‡
    let mut features = Vec::new();
    let last_idx = prices.len() - 1;
    
    // ä¸ºæ¯ä¸ªç‰¹å¾è®¡ç®—å€¼
    for feature_name in &metadata.features {
        match feature_name.as_str() {
            "close" => {
                // å½’ä¸€åŒ–æ”¶ç›˜ä»·
                let price_min = prices.iter().fold(f64::INFINITY, |a, &b| a.min(b));
                let price_max = prices.iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));
                let price_range = price_max - price_min;
                let normalized = if price_range > 0.0 {
                    (current_price - price_min) / price_range
                } else {
                    0.5 // å¦‚æœä»·æ ¼æ²¡æœ‰å˜åŒ–ï¼Œä½¿ç”¨ä¸­é—´å€¼
                };
                features.push(normalized);
            },
            "volume" => {
                // å½’ä¸€åŒ–æˆäº¤é‡
                let latest_volume = volumes[last_idx];
                let vol_min = volumes.iter().fold(i64::MAX, |a, &b| a.min(b));
                let vol_max = volumes.iter().fold(i64::MIN, |a, &b| a.max(b));
                let vol_range = (vol_max - vol_min) as f64;
                let normalized = if vol_range > 0.0 {
                    (latest_volume - vol_min) as f64 / vol_range
                } else {
                    0.5 // å¦‚æœæˆäº¤é‡æ²¡æœ‰å˜åŒ–ï¼Œä½¿ç”¨ä¸­é—´å€¼
                };
                features.push(normalized);
            },
            "change_percent" => {
                // è®¡ç®—ä»·æ ¼å˜åŒ–ç™¾åˆ†æ¯”
                let prev_price = prices[last_idx - 1];
                let change = (current_price - prev_price) / prev_price;
                let normalized = (change / 0.1).clamp(-1.0, 1.0); // å‡è®¾æ­£å¸¸å˜åŒ–ç‡åœ¨Â±10%å†…
                features.push(normalized);
            },
            "ma5" => {
                // 5æ—¥ç§»åŠ¨å¹³å‡çº¿
                if prices.len() >= 5 {
                    let ma5 = prices[prices.len()-5..].iter().sum::<f64>() / 5.0;
                    let normalized = (ma5 - current_price) / current_price;
                    features.push(normalized);
                } else {
                    features.push(0.0);
                }
            },
            "ma10" => {
                // 10æ—¥ç§»åŠ¨å¹³å‡çº¿
                if prices.len() >= 10 {
                    let ma10 = prices[prices.len()-10..].iter().sum::<f64>() / 10.0;
                    let normalized = (ma10 - current_price) / current_price;
                    features.push(normalized);
                } else {
                    features.push(0.0);
                }
            },
            "ma20" => {
                // 20æ—¥ç§»åŠ¨å¹³å‡çº¿
                if prices.len() >= 20 {
                    let ma20 = prices[prices.len()-20..].iter().sum::<f64>() / 20.0;
                    let normalized = (ma20 - current_price) / current_price;
                    features.push(normalized);
                } else {
                    features.push(0.0);
                }
            },
            "rsi" => {
                // RSIè®¡ç®—
                if prices.len() >= 15 {
                    let gains = prices[prices.len()-15..prices.len()-1]
                        .iter()
                        .zip(prices[prices.len()-14..].iter())
                        .map(|(prev, curr)| {
                            let diff = curr - prev;
                            if diff > 0.0 { diff } else { 0.0 }
                        })
                        .sum::<f64>() / 14.0;
                        
                    let losses = prices[prices.len()-15..prices.len()-1]
                        .iter()
                        .zip(prices[prices.len()-14..].iter())
                        .map(|(prev, curr)| {
                            let diff = prev - curr;
                            if diff > 0.0 { diff } else { 0.0 }
                        })
                        .sum::<f64>() / 14.0;
                        
                    let rsi = if losses == 0.0 { 
                        100.0 
                    } else { 
                        100.0 - (100.0 / (1.0 + (gains / losses))) 
                    };
                    
                    features.push(rsi / 100.0);
                } else {
                    features.push(0.5); // é»˜è®¤ä¸­æ€§RSI
                }
            },
            "macd" => {
                // MACDè®¡ç®—
                if prices.len() >= 26 {
                    let ema12 = prices[prices.len()-26..].iter().sum::<f64>() / 12.0;
                    let ema26 = prices[prices.len()-26..].iter().sum::<f64>() / 26.0;
                    let macd = ema12 - ema26;
                    let normalized = macd / current_price;
                    features.push(normalized);
                } else {
                    features.push(0.0);
                }
            },
            "bollinger" => {
                // å¸ƒæ—å¸¦è®¡ç®—
                if prices.len() >= 20 {
                    let ma20 = prices[prices.len()-20..].iter().sum::<f64>() / 20.0;
                    let variance = prices[prices.len()-20..]
                        .iter()
                        .map(|p| (p - ma20).powi(2))
                        .sum::<f64>() / 20.0;
                    let std_dev = variance.sqrt();
                    let upper_band = ma20 + 2.0 * std_dev;
                    let lower_band = ma20 - 2.0 * std_dev;
                    
                    // è®¡ç®—ä»·æ ¼åœ¨å¸ƒæ—å¸¦ä¸­çš„ç›¸å¯¹ä½ç½® (-1åˆ°1)
                    let position = if upper_band > lower_band {
                        2.0 * (current_price - lower_band) / (upper_band - lower_band) - 1.0
                    } else {
                        0.0
                    };
                    
                    features.push(position);
                } else {
                    features.push(0.0);
                }
            },
            "stochastic_k" => {
                // Kå€¼è®¡ç®—
                if prices.len() >= 14 {
                    let highest_high = prices[prices.len()-14..].iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));
                    let lowest_low = prices[prices.len()-14..].iter().fold(f64::INFINITY, |a, &b| a.min(b));
                    
                    let k = if highest_high > lowest_low {
                        (current_price - lowest_low) / (highest_high - lowest_low)
                    } else {
                        0.5
                    };
                    
                    features.push(k);
                } else {
                    features.push(0.5);
                }
            },
            "stochastic_d" => {
                // Då€¼è®¡ç®—(Kå€¼çš„3æ—¥ç§»åŠ¨å¹³å‡)
                if prices.len() >= 14 {
                    let highest_high = prices[prices.len()-14..].iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));
                    let lowest_low = prices[prices.len()-14..].iter().fold(f64::INFINITY, |a, &b| a.min(b));
                    
                    let k1 = if highest_high > lowest_low {
                        (current_price - lowest_low) / (highest_high - lowest_low)
                    } else {
                        0.5
                    };
                    
                    let k2 = if highest_high > lowest_low && prices.len() > 1 {
                        (prices[prices.len()-2] - lowest_low) / (highest_high - lowest_low)
                    } else {
                        0.5
                    };
                    
                    let k3 = if highest_high > lowest_low && prices.len() > 2 {
                        (prices[prices.len()-3] - lowest_low) / (highest_high - lowest_low)
                    } else {
                        0.5
                    };
                    
                    let d = (k1 + k2 + k3) / 3.0;
                    features.push(d);
                } else {
                    features.push(0.5);
                }
            },
            "momentum" => {
                // åŠ¨é‡æŒ‡æ ‡(å½“å‰ä»·æ ¼ä¸næ—¥å‰ä»·æ ¼çš„æ¯”ç‡)
                let n = 10; // ä½¿ç”¨10æ—¥åŠ¨é‡
                if prices.len() > n {
                    let price_n_days_ago = prices[prices.len()-n-1];
                    let momentum = current_price / price_n_days_ago - 1.0;
                    let normalized = (momentum / 0.2).clamp(-1.0, 1.0); // å‡è®¾æ­£å¸¸åŠ¨é‡åœ¨Â±20%å†…
                    features.push(normalized);
                } else {
                    features.push(0.0);
                }
            },
            _ => {
                // æœªçŸ¥ç‰¹å¾ï¼Œæ·»åŠ 0å€¼
                features.push(0.0);
            }
        }
    }
    
    // åˆ›å»ºè¾“å…¥å¼ é‡ï¼Œè½¬æ¢ä¸ºF32ç±»å‹ä»¥åŒ¹é…æ¨¡å‹æƒé‡
    let features_f32: Vec<f32> = features.iter().map(|&x| x as f32).collect();
    let input_tensor = Tensor::from_slice(&features_f32, &[1, features.len()], &device)
        .map_err(|e| format!("åˆ›å»ºè¾“å…¥å¼ é‡å¤±è´¥: {}", e))?;
    
    // è¿›è¡Œé¢„æµ‹
    let output = model.forward(&input_tensor)
        .map_err(|e| format!("é¢„æµ‹å¤±è´¥: {}", e))?;
    
    // å¦‚æœè¾“å‡ºæ˜¯å¤šç»´çš„ï¼Œç¡®ä¿æˆ‘ä»¬å¾—åˆ°æ­£ç¡®çš„å€¼
    println!("é¢„æµ‹è¾“å‡ºå½¢çŠ¶: {:?}", output.dims());
    let raw_change_rate = match output.dims() {
        // å¦‚æœæ˜¯1ç»´å¼ é‡ [1] æˆ– [batch_size]
        [_] => {
            output.to_vec1::<f32>().map_err(|e| format!("è·å–é¢„æµ‹ç»“æœå¤±è´¥: {}", e))?[0] as f64
        },
        // å¦‚æœæ˜¯2ç»´å¼ é‡ [batch_size, 1] æˆ– [batch_size, features]
        [_, n] => {
            if *n == 1 { // ä¿®å¤: è§£å¼•ç”¨ n
                // å¦‚æœæ˜¯ [batch_size, 1]ï¼Œç›´æ¥è·å–ç¬¬ä¸€ä¸ªå…ƒç´ 
                output.to_vec2::<f32>().map_err(|e| format!("è·å–é¢„æµ‹ç»“æœå¤±è´¥: {}", e))?[0][0] as f64
            } else {
                // å¦‚æœæ˜¯ [batch_size, features]ï¼Œè·å–ç¬¬ä¸€è¡Œç¬¬ä¸€åˆ—å…ƒç´ 
                println!("è­¦å‘Š: é¢„æµ‹è¾“å‡ºç»´åº¦ä¸é¢„æœŸä¸ç¬¦ï¼Œå°è¯•è·å–ç¬¬ä¸€ä¸ªå€¼");
                output.to_vec2::<f32>().map_err(|e| format!("è·å–é¢„æµ‹ç»“æœå¤±è´¥: {}", e))?[0][0] as f64
            }
        },
        // å…¶ä»–ç»´åº¦ï¼Œè¿”å›é”™è¯¯
        _ => {
            return Err(format!("é¢„æµ‹è¾“å‡ºç»´åº¦ä¸æ”¯æŒ: {:?}", output.dims()));
        }
    };
    
    // åŸºäºå†å²æ•°æ®è®¡ç®—çœŸå®çš„ä»·æ ¼å˜åŒ–æ¨¡å¼
    let historical_volatility = calculate_historical_volatility(&prices);
    let recent_trend = calculate_recent_trend(&prices);
    let support_resistance = calculate_support_resistance(&prices, current_price);
    
    // ğŸ¯ ä½¿ç”¨ç»¼åˆæŠ€æœ¯åˆ†æ
    let technical_signals = analyze_technical_signals(&prices, &highs, &lows, &volumes);
    
    println!("ğŸ“Š å†å²æ³¢åŠ¨ç‡: {:.4}, è¿‘æœŸè¶‹åŠ¿: {:.4}, æ”¯æ’‘é˜»åŠ›: {:.4}", 
             historical_volatility, recent_trend, support_resistance);
    println!("ğŸ“ˆ æŠ€æœ¯ä¿¡å·: {:?}, ä¿¡å·å¼ºåº¦: {:.2}, ä¹°å…¥ä¿¡å·: {}, å–å‡ºä¿¡å·: {}", 
             technical_signals.signal, technical_signals.signal_strength, 
             technical_signals.buy_signals, technical_signals.sell_signals);
    println!("ğŸ“Š åŸå§‹æ¨¡å‹é¢„æµ‹å˜åŒ–ç‡: {:.6}", raw_change_rate);
    
    // ç”Ÿæˆé¢„æµ‹
    let mut predictions: Vec<Prediction> = Vec::new();
    let mut last_price = current_price;
    
    // è·å–æœ€åä¸€ä¸ªæ—¥æœŸï¼Œç”¨äºè®¡ç®—é¢„æµ‹æ—¥æœŸ
    let last_date = chrono::NaiveDate::parse_from_str(&dates.last().unwrap_or(&"2023-01-01".to_string()), "%Y-%m-%d")
        .unwrap_or_else(|_| chrono::Local::now().naive_local().date());
    
    for day in 1..=request.prediction_days {
        // åˆ›å»ºç›®æ ‡æ—¥æœŸ - ä½¿ç”¨Aè‚¡äº¤æ˜“æ—¥è§„åˆ™
        let mut target_date = last_date;
        // å‘å‰æ¨è¿›æŒ‡å®šçš„äº¤æ˜“æ—¥æ•°
        for _ in 0..day {
            target_date = get_next_trading_day(target_date);
        }
        let date_str = target_date.format("%Y-%m-%d").to_string();
        
        // ğŸ¯ æ”¹è¿›çš„é¢„æµ‹ç­–ç•¥ï¼šç»“åˆæŠ€æœ¯åˆ†æçš„æ¶¨è·Œé¢„æµ‹
        
        // 1. åŸºç¡€æ¨¡å‹é¢„æµ‹ï¼ˆæ ‡å‡†åŒ–å¤„ç†ï¼‰
        let base_model_prediction = raw_change_rate.tanh() * 0.02; // é™åˆ¶åœ¨Â±2%èŒƒå›´å†…
        
        // 2. å†å²æ³¢åŠ¨æ€§è°ƒæ•´
        let volatility_factor = historical_volatility.clamp(0.01, 0.08); // é™åˆ¶æ³¢åŠ¨ç‡èŒƒå›´
        
        // 3. è¶‹åŠ¿ä¿®æ­£ï¼ˆéšæ—¶é—´è¡°å‡ï¼‰
        let trend_decay = 0.9_f64.powi(day as i32);
        let trend_factor = recent_trend * trend_decay;
        
        // 4. æŠ€æœ¯ä¿¡å·å½±å“ï¼ˆAè‚¡ç‰¹è‰²ï¼šæŠ€æœ¯åˆ†ææƒé‡è¾ƒé«˜ï¼‰
        let technical_impact = technical_signals.signal_strength * 0.03 * (0.95_f64.powi(day as i32));
        
        // 5. éšæœºå¸‚åœºå™ªéŸ³ï¼ˆæ¨¡æ‹ŸçœŸå®å¸‚åœºçš„ä¸ç¡®å®šæ€§ï¼Œè€ƒè™‘Aè‚¡æ³¢åŠ¨æ€§ï¼‰
        let market_noise = (rand::random::<f64>() - 0.5) * volatility_factor * 1.2;
        
        // 6. å‡å€¼å›å½’æ•ˆåº”ï¼ˆä»·æ ¼åç¦»å‡å€¼æ—¶çš„å›å½’å€¾å‘ï¼‰
        let mean_reversion = if prices.len() >= 20 {
            let ma20 = prices[prices.len()-20..].iter().sum::<f64>() / 20.0;
            let deviation = (last_price - ma20) / ma20;
            -deviation * 0.25 * (1.0 / day as f64) // åç¦»è¶Šå¤§ï¼Œå›å½’åŠ›è¶Šå¼º
        } else {
            0.0
        };
        
        // 7. æ”¯æ’‘é˜»åŠ›ä½å½±å“
        let sr_effect = support_resistance * 0.4;
        
        // 8. Aè‚¡ç‰¹è‰²ï¼šè¿½æ¶¨æ€è·Œå¿ƒç†ï¼ˆçŸ­æœŸåŠ¨é‡æ•ˆåº”ï¼‰
        let momentum_effect = if day <= 2 && technical_signals.buy_signals > technical_signals.sell_signals {
            0.01 // ä¹°å…¥ä¿¡å·å¤šæ—¶ï¼ŒçŸ­æœŸå¯èƒ½ç»§ç»­ä¸Šæ¶¨
        } else if day <= 2 && technical_signals.sell_signals > technical_signals.buy_signals {
            -0.01 // å–å‡ºä¿¡å·å¤šæ—¶ï¼ŒçŸ­æœŸå¯èƒ½ç»§ç»­ä¸‹è·Œ
        } else {
            0.0
        };
        
        // ç»¼åˆè®¡ç®—é¢„æµ‹å˜åŒ–ç‡ï¼ˆè°ƒæ•´æƒé‡ï¼Œæ›´é‡è§†æŠ€æœ¯åˆ†æï¼‰
        let mut predicted_change_rate = base_model_prediction * 0.25  // æ¨¡å‹é¢„æµ‹25%æƒé‡
            + technical_impact * 0.30                                 // æŠ€æœ¯åˆ†æ30%æƒé‡
            + trend_factor * 0.20                                    // è¶‹åŠ¿20%æƒé‡
            + market_noise * 0.10                                    // éšæœºå™ªéŸ³10%æƒé‡
            + mean_reversion * 0.08                                  // å‡å€¼å›å½’8%æƒé‡
            + sr_effect * 0.05                                       // æ”¯æ’‘é˜»åŠ›5%æƒé‡
            + momentum_effect * 0.02;                                // åŠ¨é‡æ•ˆåº”2%æƒé‡
        
        // 7. å¼•å…¥å‘¨æœŸæ€§è°ƒæ•´ï¼ˆæ¨¡æ‹Ÿå¸‚åœºçš„å‘¨æœŸæ€§æ³¢åŠ¨ï¼‰
        let cycle_adjustment = match day % 3 {
            1 => 0.0,                                                // ç¬¬1å¤©ä¿æŒåŸé¢„æµ‹
            2 => -predicted_change_rate * 0.3,                      // ç¬¬2å¤©é€‚åº¦åå‘è°ƒæ•´
            0 => predicted_change_rate * 0.2,                       // ç¬¬3å¤©å°å¹…åŒå‘è°ƒæ•´
            _ => 0.0,
        };
        predicted_change_rate += cycle_adjustment;
        
        // 8. åº”ç”¨Aè‚¡æ¶¨è·Œå¹…é™åˆ¶
        let change_percent = clamp_daily_change(predicted_change_rate * 100.0);
        let clamped_change_rate = change_percent / 100.0;
        
        // è®¡ç®—é¢„æµ‹ä»·æ ¼
        let predicted_price = last_price * (1.0 + clamped_change_rate);
        
        // ğŸ¯ æ”¹è¿›çš„ç½®ä¿¡åº¦è®¡ç®—ï¼ˆç»“åˆæŠ€æœ¯åˆ†æï¼‰
        let base_confidence = (metadata.accuracy + 0.3).min(0.8); // æå‡åŸºç¡€ç½®ä¿¡åº¦
        
        // ç½®ä¿¡åº¦å½±å“å› å­
        let volatility_impact = 1.0 - (volatility_factor * 8.0).min(0.4);     // æ³¢åŠ¨ç‡å½±å“
        let trend_strength = (recent_trend.abs() * 10.0).min(0.2);            // è¶‹åŠ¿å¼ºåº¦å¥–åŠ±
        let prediction_magnitude = 1.0 - (change_percent.abs() / 15.0).min(0.3); // é¢„æµ‹å¹…åº¦æƒ©ç½š
        let time_decay = 0.95_f64.powi(day as i32);                           // æ—¶é—´è¡°å‡
        
        // æŠ€æœ¯ä¿¡å·ä¸€è‡´æ€§
        let technical_consistency = match technical_signals.signal {
            TradingSignal::StrongBuy | TradingSignal::StrongSell => 1.15, // å¼ºçƒˆä¿¡å·æå‡ç½®ä¿¡åº¦
            TradingSignal::Buy | TradingSignal::Sell => 1.05,             // ä¸€èˆ¬ä¿¡å·è½»å¾®æå‡
            TradingSignal::Hold => 0.95,                                  // æ¨ªç›˜ä¿¡å·é™ä½ç½®ä¿¡åº¦
        };
        
        // ä¿¡å·ä¸é¢„æµ‹æ–¹å‘ä¸€è‡´æ€§
        let signal_alignment = match (&technical_signals.signal, predicted_change_rate > 0.0) {
            (TradingSignal::StrongBuy | TradingSignal::Buy, true) => 1.1,   // ä¹°å…¥ä¿¡å·ä¸ä¸Šæ¶¨é¢„æµ‹ä¸€è‡´
            (TradingSignal::StrongSell | TradingSignal::Sell, false) => 1.1, // å–å‡ºä¿¡å·ä¸ä¸‹è·Œé¢„æµ‹ä¸€è‡´
            (TradingSignal::Hold, _) => 1.0,                                // æ¨ªç›˜ä¿¡å·ä¸­æ€§
            _ => 0.9,                                                        // ä¿¡å·ä¸é¢„æµ‹ä¸ä¸€è‡´
        };
        
        let model_consistency = if day > 1 && !predictions.is_empty() {
            // æ£€æŸ¥é¢„æµ‹çš„ä¸€è‡´æ€§ï¼ˆé¿å…å‰§çƒˆæ³¢åŠ¨ï¼‰
            let prev_change = predictions.last().unwrap().predicted_change_percent;
            let change_diff = (change_percent - prev_change).abs();
            1.0 - (change_diff / 10.0).min(0.2)
        } else {
            1.0
        };
        
        let confidence = (base_confidence 
            * volatility_impact 
            * prediction_magnitude 
            * time_decay 
            * model_consistency
            * technical_consistency
            * signal_alignment
            + trend_strength * 0.1)
            .clamp(0.40, 0.90); // è°ƒæ•´ç½®ä¿¡åº¦èŒƒå›´ä¸º40%-90%
        
        // æ·»åŠ é¢„æµ‹ç»“æœï¼ˆåŒ…å«æŠ€æœ¯åˆ†æä¿¡æ¯ï¼‰
        let trading_signal_str = match &technical_signals.signal {
            TradingSignal::StrongBuy => "å¼ºçƒˆä¹°å…¥",
            TradingSignal::Buy => "ä¹°å…¥",
            TradingSignal::Hold => "æŒæœ‰",
            TradingSignal::Sell => "å–å‡º",
            TradingSignal::StrongSell => "å¼ºçƒˆå–å‡º",
        };
        
        let technical_indicators = TechnicalIndicatorValues {
            rsi: technical_signals.rsi,
            macd_histogram: technical_signals.macd_histogram,
            kdj_j: technical_signals.kdj_j,
            cci: technical_signals.cci,
            obv_trend: if technical_signals.obv > 0.0 { 1.0 } else { -1.0 }, // ç®€åŒ–çš„OBVè¶‹åŠ¿
        };
        
        predictions.push(Prediction {
            target_date: date_str,
            predicted_price,
            predicted_change_percent: change_percent,
            confidence,
            trading_signal: Some(trading_signal_str.to_string()),
            signal_strength: Some(technical_signals.signal_strength),
            technical_indicators: Some(technical_indicators),
        });
        
        // æ›´æ–°ä¸Šä¸€ä¸ªé¢„æµ‹ä»·æ ¼
        last_price = predicted_price;
        
        // è¾“å‡ºè°ƒè¯•ä¿¡æ¯
        println!("ğŸ“ˆ ç¬¬{}å¤©é¢„æµ‹: ä»·æ ¼={:.2}, å˜åŒ–={:.2}%, ç½®ä¿¡åº¦={:.2}%", 
                 day, predicted_price, change_percent, confidence * 100.0);
    }
    
    Ok(predictions)
}

// é‡æ–°è®­ç»ƒæ¨¡å‹
pub async fn retrain_candle_model(
    model_id: String,
    epochs: u32,
    batch_size: u32,
    learning_rate: f64,
) -> std::result::Result<(), String> {
    // åŠ è½½æ¨¡å‹å…ƒæ•°æ®
    let metadata = load_model_metadata(&model_id)
        .map_err(|e| format!("åŠ è½½æ¨¡å‹å…ƒæ•°æ®å¤±è´¥: {}", e))?;
    
    // æ„å»ºè®­ç»ƒè¯·æ±‚ - ä½¿ç”¨æ›´é•¿çš„æ—¶é—´èŒƒå›´
    let end_date = chrono::Local::now().naive_local().date();
    let start_date = end_date - chrono::Duration::days(500); // ä½¿ç”¨çº¦1.5å¹´çš„æ•°æ®
    
    let request = TrainingRequest {
        stock_code: metadata.stock_code.clone(),
        model_name: metadata.name.clone(),
        start_date: start_date.format("%Y-%m-%d").to_string(),
        end_date: end_date.format("%Y-%m-%d").to_string(),
        features: metadata.features.clone(),
        target: metadata.target.clone(),
        prediction_days: metadata.prediction_days,
        model_type: metadata.model_type.clone(),
        epochs: epochs as usize,
        batch_size: batch_size as usize,
        learning_rate,
        dropout: 0.2,
        train_test_split: 0.8,
    };
    
    println!("ğŸ”„ å¼€å§‹é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨æ‰©å±•çš„æ—¶é—´èŒƒå›´: {} åˆ° {}", 
             request.start_date, request.end_date);
    
    // åˆ é™¤æ—§æ¨¡å‹
    delete_model(&model_id).map_err(|e| format!("åˆ é™¤æ—§æ¨¡å‹å¤±è´¥: {}", e))?;
    
    // è®­ç»ƒæ–°æ¨¡å‹
    let result = train_candle_model(request).await?;
    
    println!("âœ… æ¨¡å‹é‡æ–°è®­ç»ƒå®Œæˆï¼Œæ–°å‡†ç¡®ç‡: {:.4}%", result.accuracy * 100.0);
    
    Ok(())
}

// è¯„ä¼°æ¨¡å‹
pub async fn evaluate_candle_model(model_id: String) -> std::result::Result<EvaluationResult, String> {
    // åŠ è½½æ¨¡å‹å…ƒæ•°æ®
    let metadata = load_model_metadata(&model_id)
        .map_err(|e| format!("åŠ è½½æ¨¡å‹å…ƒæ•°æ®å¤±è´¥: {}", e))?;
    
    // åŠ è½½æ¨¡å‹
    let device = Device::Cpu;
    
    let config = ModelConfig {
        model_type: metadata.model_type.clone(),
        input_size: metadata.features.len(),
        hidden_size: 64,
        output_size: 1,
        dropout: 0.0,
        learning_rate: 0.001,
        n_layers: 2,
        n_heads: 4,
        max_seq_len: 60,
    };
    
    let mut varmap = VarMap::new();
    let (_, model) = create_model(&config, &device)
        .map_err(|e| format!("æ¨¡å‹åˆ›å»ºå¤±è´¥: {}", e))?;
    
    let model_path = get_model_dir(&model_id).join("model.safetensors");
    varmap.load(&model_path).map_err(|e| format!("æ¨¡å‹åŠ è½½å¤±è´¥: {}", e))?;
    
    // åˆ›å»ºæµ‹è¯•æ•°æ® (åœ¨å®é™…åº”ç”¨ä¸­ï¼Œåº”ä»æ•°æ®åº“è·å–å®é™…è‚¡ç¥¨æ•°æ®)
    // è¿™é‡Œè¿›è¡ŒåŸºæœ¬çš„æ¨¡æ‹Ÿï¼Œä»¥å±•ç¤ºè¯„ä¼°è¿‡ç¨‹
    
    // æ¨¡æ‹Ÿ100å¤©çš„å†å²æ•°æ®
    let days = 100;
    let mut price = 100.0;
    let mut prices = Vec::with_capacity(days);
    let mut volumes = Vec::with_capacity(days);
    
    for i in 0..days {
        // ç”Ÿæˆä»·æ ¼(æœ‰ä¸€å®šçš„éšæœºæ³¢åŠ¨å’Œè¶‹åŠ¿)
        let trend = ((i as f64 / 30.0).sin() * 10.0) + ((i as f64 / 90.0).cos() * 5.0);
        let random = (rand::random::<f64>() - 0.5) * 4.0;
        price = price + trend * 0.01 + random;
        prices.push(price);
        
        // ç”Ÿæˆæˆäº¤é‡
        let volume = (1000000.0 * (1.0 + (rand::random::<f64>() - 0.5) * 0.3)) as i64;
        volumes.push(volume);
    }
    
    // ç”Ÿæˆç‰¹å¾çŸ©é˜µ
    let mut features_matrix = Vec::new();
    for i in 19..days {  // ä»ç¬¬20å¤©å¼€å§‹ï¼Œä¿è¯æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®è®¡ç®—æŒ‡æ ‡
        let mut feature_vector = Vec::new();
        
        for feature_name in &metadata.features {
            match feature_name.as_str() {
                "close" => {
                    let normalized = (prices[i] - 95.0) / 20.0;
                    feature_vector.push(normalized);
                },
                "volume" => {
                    let normalized = volumes[i] as f64 / 2000000.0;
                    feature_vector.push(normalized);
                },
                "change_percent" => {
                    let change = (prices[i] - prices[i-1]) / prices[i-1];
                    feature_vector.push(change);
                },
                "ma5" => {
                    let ma5 = prices[i-4..=i].iter().sum::<f64>() / 5.0;
                    let normalized = (ma5 - prices[i]) / prices[i];
                    feature_vector.push(normalized);
                },
                "ma10" => {
                    let ma10 = prices[i-9..=i].iter().sum::<f64>() / 10.0;
                    let normalized = (ma10 - prices[i]) / prices[i];
                    feature_vector.push(normalized);
                },
                "ma20" => {
                    let ma20 = prices[i-19..=i].iter().sum::<f64>() / 20.0;
                    let normalized = (ma20 - prices[i]) / prices[i];
                    feature_vector.push(normalized);
                },
                "rsi" => {
                    // ç®€åŒ–çš„RSIè®¡ç®—
                    let gains = prices[i-14..i].iter()
                        .zip(prices[i-13..=i].iter())
                        .map(|(prev, curr)| {
                            let diff = curr - prev;
                            if diff > 0.0 { diff } else { 0.0 }
                        })
                        .sum::<f64>() / 14.0;
                        
                    let losses = prices[i-14..i].iter()
                        .zip(prices[i-13..=i].iter())
                        .map(|(prev, curr)| {
                            let diff = prev - curr;
                            if diff > 0.0 { diff } else { 0.0 }
                        })
                        .sum::<f64>() / 14.0;
                        
                    let rsi = if losses == 0.0 { 
                        100.0 
                    } else { 
                        100.0 - (100.0 / (1.0 + (gains / losses))) 
                    };
                    
                    feature_vector.push(rsi / 100.0);
                },
                "macd" => {
                    // ç®€åŒ–çš„MACDè®¡ç®—
                    let ema12 = prices[i-11..=i].iter().sum::<f64>() / 12.0;
                    let ema26 = prices[i-25..=i].iter().sum::<f64>() / 26.0;
                    let macd = ema12 - ema26;
                    let normalized = macd / prices[i];
                    feature_vector.push(normalized);
                },
                "bollinger" => {
                    // å¸ƒæ—å¸¦è®¡ç®—
                    let ma20 = prices[i-19..=i].iter().sum::<f64>() / 20.0;
                    let variance = prices[i-19..=i]
                        .iter()
                        .map(|p| (p - ma20).powi(2))
                        .sum::<f64>() / 20.0;
                    let std_dev = variance.sqrt();
                    let upper_band = ma20 + 2.0 * std_dev;
                    let lower_band = ma20 - 2.0 * std_dev;
                    
                    // è®¡ç®—ä»·æ ¼åœ¨å¸ƒæ—å¸¦ä¸­çš„ç›¸å¯¹ä½ç½® (-1åˆ°1)
                    let position = if upper_band == lower_band {
                        0.0
                    } else {
                        2.0 * (prices[i] - lower_band) / (upper_band - lower_band) - 1.0
                    };
                    
                    feature_vector.push(position);
                },
                "stochastic_k" => {
                    // Kå€¼è®¡ç®—
                    let highest_high = prices[i-13..=i].iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));
                    let lowest_low = prices[i-13..=i].iter().fold(f64::INFINITY, |a, &b| a.min(b));
                    
                    let k = if highest_high == lowest_low {
                        0.5
                    } else {
                        (prices[i] - lowest_low) / (highest_high - lowest_low)
                    };
                    
                    feature_vector.push(k);
                },
                "stochastic_d" => {
                    // Kå€¼è®¡ç®—
                    let highest_high = prices[i-13..=i].iter().fold(f64::NEG_INFINITY, |a, &b| a.max(b));
                    let lowest_low = prices[i-13..=i].iter().fold(f64::INFINITY, |a, &b| a.min(b));
                    
                    let k1 = if highest_high == lowest_low {
                        0.5
                    } else {
                        (prices[i] - lowest_low) / (highest_high - lowest_low)
                    };
                    
                    let k2 = if highest_high == lowest_low {
                        0.5
                    } else {
                        (prices[i-1] - lowest_low) / (highest_high - lowest_low)
                    };
                    
                    let k3 = if highest_high == lowest_low {
                        0.5
                    } else {
                        (prices[i-2] - lowest_low) / (highest_high - lowest_low)
                    };
                    
                    let d = (k1 + k2 + k3) / 3.0;
                    feature_vector.push(d);
                },
                "momentum" => {
                    // åŠ¨é‡æŒ‡æ ‡(å½“å‰ä»·æ ¼ä¸10æ—¥å‰ä»·æ ¼çš„æ¯”ç‡)
                    if i >= 29 {
                        let momentum = prices[i] / prices[i-10] - 1.0;
                        feature_vector.push(momentum);
                    } else {
                        feature_vector.push(0.0);
                    }
                },
                _ => {
                    // æœªçŸ¥ç‰¹å¾ï¼Œæ·»åŠ 0å€¼
                    feature_vector.push(0.0);
                }
            }
        }
        
        features_matrix.push(feature_vector);
    }
    
    // ç”Ÿæˆç›®æ ‡å˜é‡: ä½¿ç”¨5å¤©åçš„ä»·æ ¼å˜åŒ–ç‡
    let pred_days = metadata.prediction_days;
    let mut targets = Vec::new();
    
    // ä»·æ ¼ä»ç¬¬20å¤©å¼€å§‹
    let prices_offset = 20;
    
    for i in 0..features_matrix.len() - pred_days {
        let current_price = prices[i + prices_offset];
        let future_price = prices[i + prices_offset + pred_days];
        
        // è®¡ç®—æœªæ¥ä»·æ ¼ç›¸å¯¹å½“å‰ä»·æ ¼çš„å˜åŒ–ç‡
        let change_rate = (future_price - current_price) / current_price;
        
        // å°†å˜åŒ–ç‡åˆ†ç±»ä¸ºä¸Šæ¶¨/ä¸‹è·Œ/æŒå¹³
        let target = if change_rate > 0.01 {
            1.0  // æ˜æ˜¾ä¸Šæ¶¨
        } else if change_rate < -0.01 {
            -1.0 // æ˜æ˜¾ä¸‹è·Œ
        } else {
            0.0  // åŸºæœ¬æŒå¹³
        };
        
        targets.push(target);
    }
    
    // æˆªæ–­ç‰¹å¾çŸ©é˜µï¼Œä½¿å…¶ä¸ç›®æ ‡å˜é‡é•¿åº¦åŒ¹é…
    features_matrix.truncate(targets.len());
    
    // å°†ç‰¹å¾å’Œç›®æ ‡è½¬æ¢ä¸ºå¼ é‡ï¼Œä½¿ç”¨F32ç±»å‹ä»¥åŒ¹é…æ¨¡å‹æƒé‡
    let features_len = features_matrix[0].len();
    let test_size = features_matrix.len();
    
    let x_test_vec: Vec<f64> = features_matrix.iter()
        .flat_map(|v| v.iter().copied())
        .collect();
    
    let x_test_f32: Vec<f32> = x_test_vec.iter().map(|&x| x as f32).collect();
    let x_test = Tensor::from_slice(&x_test_f32, &[test_size, features_len], &device)
        .map_err(|e| format!("åˆ›å»ºæµ‹è¯•ç‰¹å¾å¼ é‡å¤±è´¥: {}", e))?;
    
    // è¿›è¡Œé¢„æµ‹
    let y_pred = model.forward(&x_test)
        .map_err(|e| format!("é¢„æµ‹å¤±è´¥: {}", e))?;
    
    // ç¡®ä¿é¢„æµ‹è¾“å‡ºçš„å½¢çŠ¶ä¸ç›®æ ‡éœ€æ±‚ä¸€è‡´
    println!("é¢„æµ‹è¾“å‡ºå½¢çŠ¶: {:?}, æµ‹è¯•æ•°æ®å¤§å°: {}", y_pred.dims(), test_size);
    let y_pred_adjusted = if y_pred.dims().len() == 2 && y_pred.dims()[1] != 1 {
        // å¦‚æœè¾“å‡ºæ˜¯ [test_size, N] å½¢çŠ¶ï¼ˆN > 1ï¼‰ï¼Œå–ç¬¬ä¸€åˆ—ä½œä¸ºé¢„æµ‹ç»“æœ
        println!("è°ƒæ•´é¢„æµ‹è¾“å‡ºï¼Œä»å¤šåˆ—å˜ä¸ºå•åˆ—");
        y_pred.narrow(1, 0, 1).map_err(|e| format!("è°ƒæ•´é¢„æµ‹å½¢çŠ¶å¤±è´¥: {}", e))?
    } else if y_pred.dims().len() == 1 {
        // å¦‚æœè¾“å‡ºæ˜¯ [test_size] å½¢çŠ¶ï¼Œé‡å¡‘ä¸º [test_size, 1]
        println!("è°ƒæ•´é¢„æµ‹è¾“å‡ºï¼Œä»1ç»´å˜ä¸º2ç»´");
        y_pred.reshape(&[test_size, 1]).map_err(|e| format!("è°ƒæ•´é¢„æµ‹å½¢çŠ¶å¤±è´¥: {}", e))?
    } else {
        // å…¶ä»–æƒ…å†µä¸‹ä¿æŒåŸæ ·
        y_pred
    };
    
    // æå–é¢„æµ‹ç»“æœ
    let y_pred_vec = match y_pred_adjusted.dims().len() {
        1 => {
            // å¦‚æœæ˜¯1ç»´å¼ é‡
            y_pred_adjusted.to_vec1::<f32>().map_err(|e| format!("è½¬æ¢1ç»´é¢„æµ‹ç»“æœå¤±è´¥: {}", e))?
                .into_iter().map(|x| x as f64).collect::<Vec<f64>>()
        },
        2 => {
            // å¦‚æœæ˜¯2ç»´å¼ é‡ [test_size, 1]
            let vec2d = y_pred_adjusted.to_vec2::<f32>().map_err(|e| format!("è½¬æ¢2ç»´é¢„æµ‹ç»“æœå¤±è´¥: {}", e))?;
            vec2d.into_iter().map(|row| row[0] as f64).collect::<Vec<f64>>()
        },
        _ => {
            // å¦‚æœæ˜¯å…¶ä»–ç»´åº¦ï¼Œå°è¯•å±•å¹³
            let flat = y_pred_adjusted.flatten_all().map_err(|e| format!("å±•å¹³é¢„æµ‹ç»“æœå¤±è´¥: {}", e))?;
            flat.to_vec1::<f32>().map_err(|e| format!("è½¬æ¢å±•å¹³é¢„æµ‹ç»“æœå¤±è´¥: {}", e))?
                .into_iter().map(|x| x as f64).collect::<Vec<f64>>()
        }
    };
    
    // è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    let mut correct = 0;
    let mut confusion_matrix = vec![vec![0; 3]; 3];  // 3x3çŸ©é˜µ: [ä¸‹è·Œ, æŒå¹³, ä¸Šæ¶¨]
    
    for (i, &pred_val) in y_pred_vec.iter().enumerate() {
        let actual_val = targets[i];
        
        // å°†é¢„æµ‹çš„å˜åŒ–ç‡è½¬æ¢ä¸ºç±»åˆ«
        let pred_class = if pred_val > 0.01 {
            1.0  // ä¸Šæ¶¨
        } else if pred_val < -0.01 {
            -1.0 // ä¸‹è·Œ
        } else {
            0.0  // æŒå¹³
        };
        
        // æ›´æ–°æ­£ç¡®é¢„æµ‹è®¡æ•°
        if (pred_class > 0.0 && actual_val > 0.0) || 
           (pred_class < 0.0 && actual_val < 0.0) || 
           (pred_class == 0.0 && actual_val == 0.0) {
            correct += 1;
        }
        
        // æ›´æ–°æ··æ·†çŸ©é˜µ
        let actual_idx = match actual_val {
            -1.0 => 0, // ä¸‹è·Œ
            0.0 => 1,  // æŒå¹³
            _ => 2,    // ä¸Šæ¶¨
        };
        
        let pred_idx = match pred_class {
            -1.0 => 0, // ä¸‹è·Œ
            0.0 => 1,  // æŒå¹³
            _ => 2,    // ä¸Šæ¶¨
        };
        
        confusion_matrix[actual_idx][pred_idx] += 1;
    }
    
    // è®¡ç®—å‡†ç¡®ç‡
    let accuracy = correct as f64 / targets.len() as f64;
    
    // è®¡ç®—F1åˆ†æ•°ã€ç²¾ç¡®ç‡å’Œå¬å›ç‡(é’ˆå¯¹ä¸Šæ¶¨ç±»åˆ«)
    let true_positives = confusion_matrix[2][2]; // å®é™…ä¸Šæ¶¨ï¼Œé¢„æµ‹ä¸Šæ¶¨
    let false_positives = confusion_matrix[0][2] + confusion_matrix[1][2]; // å®é™…éä¸Šæ¶¨ï¼Œé¢„æµ‹ä¸Šæ¶¨
    let false_negatives = confusion_matrix[2][0] + confusion_matrix[2][1]; // å®é™…ä¸Šæ¶¨ï¼Œé¢„æµ‹éä¸Šæ¶¨
    
    let precision = if true_positives + false_positives > 0 {
        true_positives as f64 / (true_positives + false_positives) as f64
    } else {
        0.0
    };
    
    let recall = if true_positives + false_negatives > 0 {
        true_positives as f64 / (true_positives + false_negatives) as f64
    } else {
        0.0
    };
    
    let f1_score = if precision + recall > 0.0 {
        2.0 * precision * recall / (precision + recall)
    } else {
        0.0
    };
    
    // ä¿å­˜ä¸€äº›é¢„æµ‹ç¤ºä¾‹
    let mut prediction_examples = Vec::new();
    let max_examples = std::cmp::min(10, targets.len());
    
    for i in 0..max_examples {
        prediction_examples.push(PredictionExample {
            actual: targets[i],
            predicted: y_pred_vec[i],
            features: features_matrix[i].clone(),
        });
    }
    
    // è¿”å›è¯„ä¼°ç»“æœ
    Ok(EvaluationResult {
        accuracy,
        confusion_matrix,
        precision,
        recall,
        f1_score,
        prediction_examples,
    })
}



// Aè‚¡äº¤æ˜“è§„åˆ™å·¥å…·å‡½æ•°
fn is_trading_day(date: chrono::NaiveDate) -> bool {
    match date.weekday() {
        Weekday::Mon | Weekday::Tue | Weekday::Wed | Weekday::Thu | Weekday::Fri => {
            // è¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥æ·»åŠ èŠ‚å‡æ—¥åˆ¤æ–­
            // æš‚æ—¶åªåˆ¤æ–­å·¥ä½œæ—¥
            true
        },
        _ => false
    }
}

fn get_next_trading_day(date: chrono::NaiveDate) -> chrono::NaiveDate {
    let mut next_date = date + chrono::Duration::days(1);
    while !is_trading_day(next_date) {
        next_date += chrono::Duration::days(1);
    }
    next_date
}

fn clamp_daily_change(change_percent: f64) -> f64 {
    // Aè‚¡æ¶¨è·Œåœé™åˆ¶ï¼šÂ±10%
    change_percent.clamp(-10.0, 10.0)
}

// è®¡ç®—å†å²æ³¢åŠ¨ç‡
fn calculate_historical_volatility(prices: &[f64]) -> f64 {
    if prices.len() < 20 {
        return 0.02; // é»˜è®¤2%æ³¢åŠ¨ç‡
    }
    
    // è®¡ç®—è¿‡å»20å¤©çš„ä»·æ ¼å˜åŒ–ç‡
    let mut daily_returns = Vec::new();
    for i in 1..std::cmp::min(21, prices.len()) {
        let return_rate = (prices[prices.len() - i] - prices[prices.len() - i - 1]) / prices[prices.len() - i - 1];
        daily_returns.push(return_rate);
    }
    
    // è®¡ç®—æ ‡å‡†å·®
    let mean = daily_returns.iter().sum::<f64>() / daily_returns.len() as f64;
    let variance = daily_returns.iter()
        .map(|x| (x - mean).powi(2))
        .sum::<f64>() / daily_returns.len() as f64;
    
    variance.sqrt().min(0.1) // é™åˆ¶æœ€å¤§æ³¢åŠ¨ç‡ä¸º10%
}

// è®¡ç®—è¿‘æœŸè¶‹åŠ¿
fn calculate_recent_trend(prices: &[f64]) -> f64 {
    if prices.len() < 10 {
        return 0.0;
    }
    
    let recent_len = std::cmp::min(10, prices.len());
    let recent_prices = &prices[prices.len() - recent_len..];
    
    // ä½¿ç”¨ç®€å•çº¿æ€§å›å½’è®¡ç®—è¶‹åŠ¿
    let n = recent_len as f64;
    let sum_x = (0..recent_len).sum::<usize>() as f64;
    let sum_y = recent_prices.iter().sum::<f64>();
    let sum_xy = recent_prices.iter().enumerate()
        .map(|(i, &price)| i as f64 * price)
        .sum::<f64>();
    let sum_x2 = (0..recent_len).map(|i| (i * i) as f64).sum::<f64>();
    
    // è¶‹åŠ¿æ–œç‡
    let slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x);
    let avg_price = sum_y / n;
    
    // æ ‡å‡†åŒ–è¶‹åŠ¿ (ç›¸å¯¹äºå¹³å‡ä»·æ ¼)
    (slope / avg_price).clamp(-0.05, 0.05) // é™åˆ¶åœ¨Â±5%èŒƒå›´å†…
}

// è®¡ç®—æ”¯æ’‘é˜»åŠ›ä½
fn calculate_support_resistance(prices: &[f64], current_price: f64) -> f64 {
    if prices.len() < 30 {
        return 0.01; // é»˜è®¤1%å½±å“
    }
    
    let recent_len = std::cmp::min(30, prices.len());
    let recent_prices = &prices[prices.len() - recent_len..];
    
    // å¯»æ‰¾å±€éƒ¨é«˜ç‚¹å’Œä½ç‚¹
    let mut highs = Vec::new();
    let mut lows = Vec::new();
    
    for i in 1..recent_prices.len() - 1 {
        if recent_prices[i] > recent_prices[i-1] && recent_prices[i] > recent_prices[i+1] {
            highs.push(recent_prices[i]);
        }
        if recent_prices[i] < recent_prices[i-1] && recent_prices[i] < recent_prices[i+1] {
            lows.push(recent_prices[i]);
        }
    }
    
    // æ‰¾åˆ°æœ€è¿‘çš„æ”¯æ’‘ä½å’Œé˜»åŠ›ä½
    let resistance = highs.iter().fold(0.0, |acc, &x| if x > current_price && (acc == 0.0 || x < acc) { x } else { acc });
    let support = lows.iter().fold(0.0, |acc, &x| if x < current_price && x > acc { x } else { acc });
    
    // è®¡ç®—æ”¯æ’‘é˜»åŠ›å½±å“
    let sr_strength = if resistance > 0.0 && support > 0.0 {
        let resistance_dist = (resistance - current_price) / current_price;
        let support_dist = (current_price - support) / current_price;
        (resistance_dist - support_dist) * 0.5 // å¹³è¡¡æ”¯æ’‘é˜»åŠ›å½±å“
    } else if resistance > 0.0 {
        (resistance - current_price) / current_price * 0.3
    } else if support > 0.0 {
        (current_price - support) / current_price * 0.3
    } else {
        0.0
    };
    
    sr_strength.clamp(-0.03, 0.03) // é™åˆ¶åœ¨Â±3%èŒƒå›´å†…
}



// æ–°å¢ï¼šæ¶¨è·Œæ–¹å‘åˆ†ç±»é¢„æµ‹ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DirectionPrediction {
    pub target_date: String,
    pub predicted_direction: String, // "ä¸Šæ¶¨", "ä¸‹è·Œ", "æ¨ªç›˜"
    pub direction_confidence: f64,   // æ–¹å‘é¢„æµ‹ç½®ä¿¡åº¦
    pub predicted_price: f64,        // é¢„æµ‹ä»·æ ¼ï¼ˆä»…ä¾›å‚è€ƒï¼‰
    pub predicted_change_percent: f64,
    pub confidence: f64,
}

// æ–°å¢ï¼šæ¶¨è·Œæ–¹å‘åˆ†ç±»æšä¸¾
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum Direction {
    Up,    // ä¸Šæ¶¨ > 0.5%
    Down,  // ä¸‹è·Œ < -0.5%
    Flat,  // æ¨ªç›˜ [-0.5%, 0.5%]
}

impl Direction {
    fn from_change_percent(change: f64) -> Self {
        if change > 0.5 {
            Direction::Up
        } else if change < -0.5 {
            Direction::Down
        } else {
            Direction::Flat
        }
    }
}



// æ–°å¢ï¼šæ”¹è¿›çš„å‡†ç¡®ç‡è®¡ç®—ï¼Œæ›´åŠ é‡è§†æ–¹å‘é¢„æµ‹
fn calculate_direction_focused_accuracy(predictions: &[f64], actuals: &[f64]) -> (f64, f64) {
    if predictions.len() != actuals.len() || predictions.is_empty() {
        return (0.0, 0.0);
    }
    
    let mut direction_correct = 0;
    let mut total_predictions = 0;
    let mut price_error_sum = 0.0;
    
    for i in 1..predictions.len().min(actuals.len()) {
        // è®¡ç®—é¢„æµ‹å’Œå®é™…çš„å˜åŒ–æ–¹å‘
        let pred_change = predictions[i] - predictions[i-1];
        let actual_change = actuals[i] - actuals[i-1];
        
        // æ–¹å‘åˆ†ç±»ï¼ˆä½¿ç”¨æ›´ä¸¥æ ¼çš„é˜ˆå€¼ï¼‰
        let pred_direction = Direction::from_change_percent(pred_change / predictions[i-1] * 100.0);
        let actual_direction = Direction::from_change_percent(actual_change / actuals[i-1] * 100.0);
        
        // æ–¹å‘å‡†ç¡®æ€§æ£€æŸ¥
        if pred_direction == actual_direction {
            direction_correct += 1;
        }
        
        // ä»·æ ¼å‡†ç¡®æ€§ï¼ˆç›¸å¯¹è¯¯å·®ï¼‰
        let relative_error = ((predictions[i] - actuals[i]) / actuals[i]).abs();
        price_error_sum += relative_error;
        
        total_predictions += 1;
    }
    
    if total_predictions == 0 {
        return (0.0, 0.0);
    }
    
    let direction_accuracy = direction_correct as f64 / total_predictions as f64;
    let price_accuracy = (1.0 - (price_error_sum / total_predictions as f64)).max(0.0);
    
    // æ–¹å‘å‡†ç¡®ç‡æƒé‡æé«˜åˆ°70%ï¼Œä»·æ ¼å‡†ç¡®ç‡30%
    let combined_accuracy = direction_accuracy * 0.7 + price_accuracy * 0.3;
    
    (direction_accuracy, combined_accuracy.min(0.85)) // é™åˆ¶æœ€é«˜å‡†ç¡®ç‡ä¿æŒç°å®æ€§
}

// ä»æ•°æ®åº“è·å–æœ€è¿‘çš„å¸‚åœºæ•°æ®
async fn get_recent_market_data(symbol: &str, days: usize) -> Result<(f64, Vec<String>, Vec<f64>, Vec<i64>, Vec<f64>, Vec<f64>), String> {
    // åˆ›å»ºä¸´æ—¶æ•°æ®åº“è¿æ¥
    use sqlx::sqlite::SqlitePoolOptions;
    use chrono::Local;
    
    // è®¡ç®—å¼€å§‹æ—¥æœŸï¼ˆå¤§å¹…å¢åŠ æ•°æ®è·å–èŒƒå›´ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®è¿›è¡ŒæŠ€æœ¯åˆ†æï¼‰
    let end_date = Local::now().naive_local().date();
    let buffer_days = 60; // å¢åŠ ç¼“å†²æœŸåˆ°60å¤©ï¼Œåº”å¯¹èŠ‚å‡æ—¥
    // è‡³å°‘è·å–1å¹´çš„æ•°æ®ï¼Œæˆ–è€…ç”¨æˆ·æŒ‡å®šå¤©æ•°+ç¼“å†²æœŸï¼Œå–æ›´å¤§å€¼
    let total_days = std::cmp::max(365, days + buffer_days); 
    let start_date = end_date - chrono::Duration::days(total_days as i64);
    
    // ä½¿ç”¨åŠ¨æ€æ•°æ®åº“è·¯å¾„æŸ¥æ‰¾
    let db_path = find_database_path()
        .ok_or_else(|| "æ‰¾ä¸åˆ°æ•°æ®åº“æ–‡ä»¶".to_string())?;
    
    let connection_string = format!("sqlite://{}", db_path.display());
    let pool = SqlitePoolOptions::new()
        .max_connections(1)
        .connect(&connection_string)
        .await
        .map_err(|e| format!("è¿æ¥æ•°æ®åº“å¤±è´¥: {}", e))?;
    
    // ä¿®æ”¹æŸ¥è¯¢ï¼Œè·å–æ›´å¤šå†å²æ•°æ®ä½†ä¿æŒåˆç†çš„é™åˆ¶
    let limit = std::cmp::max(300, days * 2); // è‡³å°‘300æ¡è®°å½•ï¼Œæˆ–è€…è¯·æ±‚å¤©æ•°çš„2å€
    let records = sqlx::query_as::<_, HistoricalDataType>(
        r#"SELECT * FROM historical_data 
           WHERE symbol = ? AND date BETWEEN ? AND ?
           ORDER BY date DESC
           LIMIT ?"#
    )
    .bind(symbol)
    .bind(start_date.format("%Y-%m-%d").to_string())
    .bind(end_date.format("%Y-%m-%d").to_string())
    .bind(limit as i32)
    .fetch_all(&pool)
    .await
    .map_err(|e| format!("æŸ¥è¯¢å†å²æ•°æ®å¤±è´¥: {}", e))?;
    
    if records.is_empty() {
        return Err(format!("æœªæ‰¾åˆ°è‚¡ç¥¨ä»£ç  {} çš„å†å²æ•°æ®", symbol));
    }
    
    // åå‘æ’åºä»¥è·å–æ—¶é—´é¡ºåºï¼ˆä»æ—§åˆ°æ–°ï¼‰
    let mut sorted_records = records;
    sorted_records.reverse();
    
    // æå–æ•°æ®
    let dates: Vec<String> = sorted_records.iter().map(|r| r.date.clone()).collect();
    let prices: Vec<f64> = sorted_records.iter().map(|r| r.close).collect();
    let volumes: Vec<i64> = sorted_records.iter().map(|r| r.volume).collect();
    let highs: Vec<f64> = sorted_records.iter().map(|r| r.high).collect();
    let lows: Vec<f64> = sorted_records.iter().map(|r| r.low).collect();
    
    // è·å–æœ€æ–°ä»·æ ¼
    let current_price = prices.last().copied().unwrap_or(0.0);
    
    println!("ğŸ“Š è·å–åˆ°{}æ¡å†å²æ•°æ®ç”¨äºé¢„æµ‹ï¼Œæ—¶é—´èŒƒå›´: {} åˆ° {}", 
             sorted_records.len(),
             sorted_records.first().map(|r| &r.date).unwrap_or(&"æœªçŸ¥".to_string()),
             sorted_records.last().map(|r| &r.date).unwrap_or(&"æœªçŸ¥".to_string()));
    
    Ok((current_price, dates, prices, volumes, highs, lows))
}
