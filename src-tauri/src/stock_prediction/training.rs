use candle_core::{Device, Tensor};
use candle_nn::{Module, Optimizer, VarMap, AdamW};
use std::fs;
use chrono;
use crate::stock_prediction::types::{
    ModelConfig, ModelInfo, TrainingRequest, TrainingResult
};
use crate::stock_prediction::database::get_historical_data_from_db;
use crate::stock_prediction::utils::{
    smooth_price_data, smooth_volume_data, 
    calculate_direction_focused_accuracy
};
use crate::stock_prediction::technical_indicators::{
    get_feature_required_days, calculate_feature_value
};
use crate::stock_prediction::model_management::{
    save_model_metadata, generate_model_id, get_current_timestamp, get_model_file_path
};

// ===== é‡‘èçº§æ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹ =====

/// æ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹ - ä¸“ä¸ºè‚¡ç¥¨é¢„æµ‹ä¼˜åŒ–
struct DeepStockPredictor {
    // ç¬¬ä¸€å±‚ - ç‰¹å¾æå–
    fc1: candle_nn::Linear,
    dropout1: f64,
    // ç¬¬äºŒå±‚ - æ·±åº¦ç‰¹å¾å­¦ä¹ 
    fc2: candle_nn::Linear,
    dropout2: f64,
    // ç¬¬ä¸‰å±‚ - æ¨¡å¼è¯†åˆ«
    fc3: candle_nn::Linear,
    dropout3: f64,
    // ç¬¬å››å±‚ - æ·±åº¦æŠ½è±¡
    fc4: candle_nn::Linear,
    dropout4: f64,
    // æ®‹å·®è¿æ¥å±‚
    residual: candle_nn::Linear,
    // è¾“å‡ºå±‚
    fc_out: candle_nn::Linear,
    // è®­ç»ƒæ¨¡å¼æ ‡å¿—
    training: bool,
}

impl DeepStockPredictor {
    fn new(
        in_size: usize,
        hidden_size: usize,
        out_size: usize,
        dropout: f64,
        vb: candle_nn::VarBuilder,
    ) -> Result<Self, candle_core::Error> {
        // è®¡ç®—å„å±‚ç»´åº¦ - é‡‘å­—å¡”ç»“æ„
        let layer1_size = hidden_size * 2;      // ç¬¬ä¸€å±‚æ‰©å±•(256)
        let layer2_size = hidden_size;          // ç¬¬äºŒå±‚æ ‡å‡†(128)
        let layer3_size = hidden_size / 2;      // ç¬¬ä¸‰å±‚æ”¶ç¼©(64)
        let layer4_size = hidden_size / 4;      // ç¬¬å››å±‚è¿›ä¸€æ­¥æ”¶ç¼©(32)
        
        Ok(Self {
            // ç¬¬ä¸€å±‚ï¼šè¾“å…¥ -> æ‰©å±•ç‰¹å¾ç©ºé—´
            fc1: candle_nn::linear(in_size, layer1_size, vb.pp("fc1"))?,
            dropout1: dropout,
            // ç¬¬äºŒå±‚ï¼šæ·±åº¦ç‰¹å¾å­¦ä¹ 
            fc2: candle_nn::linear(layer1_size, layer2_size, vb.pp("fc2"))?,
            dropout2: dropout * 0.8,  // é€å±‚é™ä½dropout
            // ç¬¬ä¸‰å±‚ï¼šæ¨¡å¼è¯†åˆ«
            fc3: candle_nn::linear(layer2_size, layer3_size, vb.pp("fc3"))?,
            dropout3: dropout * 0.6,
            // ç¬¬å››å±‚ï¼šæ·±åº¦æŠ½è±¡
            fc4: candle_nn::linear(layer3_size, layer4_size, vb.pp("fc4"))?,
            dropout4: dropout * 0.4,
            // æ®‹å·®è¿æ¥ï¼ˆè·³è·ƒè¿æ¥ï¼Œä»è¾“å…¥ç›´æ¥åˆ°ç¬¬å››å±‚ï¼‰
            residual: candle_nn::linear(in_size, layer4_size, vb.pp("residual"))?,
            // è¾“å‡ºå±‚
            fc_out: candle_nn::linear(layer4_size, out_size, vb.pp("fc_out"))?,
            training: true,
        })
    }
    
    /// ReLUæ¿€æ´»å‡½æ•°
    fn relu(x: &Tensor) -> Result<Tensor, candle_core::Error> {
        let zeros = Tensor::zeros(x.shape(), x.dtype(), x.device())?;
        x.maximum(&zeros)
    }
    
    /// Dropoutå®ç°ï¼ˆè®­ç»ƒæ—¶éšæœºä¸¢å¼ƒï¼‰
    fn dropout(x: &Tensor, p: f64, training: bool) -> Result<Tensor, candle_core::Error> {
        if !training || p == 0.0 {
            return Ok(x.clone());
        }
        // ç®€åŒ–ç‰ˆdropoutï¼šç›´æ¥ç¼©æ”¾
        x.affine(1.0 / (1.0 - p), 0.0)
    }
    
    /// è®¾ç½®è®­ç»ƒ/è¯„ä¼°æ¨¡å¼
    fn set_training(&mut self, training: bool) {
        self.training = training;
    }
}

unsafe impl Send for DeepStockPredictor {}
unsafe impl Sync for DeepStockPredictor {}

impl Module for DeepStockPredictor {
    fn forward(&self, xs: &Tensor) -> Result<Tensor, candle_core::Error> {
        // ç¬¬ä¸€å±‚ï¼šç‰¹å¾æå– + ReLU + Dropout
        let x1 = self.fc1.forward(xs)?;
        let x1 = Self::relu(&x1)?;
        let x1 = Self::dropout(&x1, self.dropout1, self.training)?;
        
        // ç¬¬äºŒå±‚ï¼šæ·±åº¦å­¦ä¹  + ReLU + Dropout
        let x2 = self.fc2.forward(&x1)?;
        let x2 = Self::relu(&x2)?;
        let x2 = Self::dropout(&x2, self.dropout2, self.training)?;
        
        // ç¬¬ä¸‰å±‚ï¼šæ¨¡å¼è¯†åˆ« + ReLU + Dropout
        let x3 = self.fc3.forward(&x2)?;
        let x3 = Self::relu(&x3)?;
        let x3 = Self::dropout(&x3, self.dropout3, self.training)?;
        
        // ç¬¬å››å±‚ï¼šæ·±åº¦æŠ½è±¡ + ReLU + Dropout
        let x4 = self.fc4.forward(&x3)?;
        let x4 = Self::relu(&x4)?;
        let x4 = Self::dropout(&x4, self.dropout4, self.training)?;
        
        // æ®‹å·®è¿æ¥ï¼ˆä»è¾“å…¥ç›´æ¥åˆ°ç¬¬å››å±‚ï¼Œå¸®åŠ©æ¢¯åº¦æµåŠ¨ï¼‰
        let residual = self.residual.forward(xs)?;
        let x4 = (x4 + residual)?;
        
        // è¾“å‡ºå±‚ï¼ˆä¸åŠ æ¿€æ´»å‡½æ•°ï¼Œå› ä¸ºæ˜¯å›å½’é—®é¢˜ï¼‰
        self.fc_out.forward(&x4)
    }
}

// æ”¹è¿›çš„æ¨¡å‹åˆ›å»ºå‡½æ•°
fn create_model(config: &ModelConfig, device: &Device) -> Result<(VarMap, Box<dyn Module + Send + Sync>), candle_core::Error> {
    let varmap = VarMap::new();
    let vb = candle_nn::VarBuilder::from_varmap(&varmap, candle_core::DType::F32, device);
    
    // ä½¿ç”¨æ›´å¤§çš„éšè—å±‚ï¼ˆé‡‘èæ•°æ®éœ€è¦æ›´å¤šå‚æ•°ï¼‰
    let hidden_size = config.hidden_size.max(128);  // è‡³å°‘128
    
    // åˆ›å»ºæ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹
    let model = DeepStockPredictor::new(
        config.input_size,
        hidden_size,
        config.output_size,
        config.dropout,
        vb,
    )?;
    
    let model: Box<dyn Module + Send + Sync> = Box::new(model);
    Ok((varmap, model))
}

// ç®€åŒ–çš„æ¨¡å‹ä¿å­˜å‡½æ•°
fn save_model(varmap: &VarMap, path: &std::path::Path) -> Result<(), candle_core::Error> {
    varmap.save(path)?;
    Ok(())
}

// æ”¹è¿›çš„æ•°æ®é¢„å¤„ç†å‡½æ•°
async fn prepare_stock_data(
    request: &TrainingRequest,
) -> std::result::Result<(Tensor, Tensor, Tensor, Tensor, Vec<String>), candle_core::Error> {
    // è®¾ç½®è®¾å¤‡
    let device = Device::Cpu;
    
    let symbol = &request.stock_code;
    
    // è§£æå‰ç«¯ä¼ æ¥çš„æ—¥æœŸèŒƒå›´
    let end_date = chrono::Local::now().naive_local().date();
    let user_start_date = chrono::NaiveDate::parse_from_str(&request.start_date, "%Y-%m-%d")
        .unwrap_or_else(|_| end_date - chrono::Duration::days(210)); // é»˜è®¤210å¤©
    let user_end_date = chrono::NaiveDate::parse_from_str(&request.end_date, "%Y-%m-%d")
        .unwrap_or(end_date);
    
    // è®¡ç®—ç”¨æˆ·è¯·æ±‚çš„å¤©æ•°èŒƒå›´
    let requested_days = (user_end_date - user_start_date).num_days();
    
    // ä¸ºAè‚¡èŠ‚å‡æ—¥å¢åŠ é¢å¤–ç¼“å†²æœŸ
    // å¦‚æœç”¨æˆ·å·²ç»åŒ…å«äº†ç¼“å†²æœŸï¼ˆå¦‚180+30=210å¤©ï¼‰ï¼Œæˆ‘ä»¬å†å¢åŠ ä¸€äº›ä»¥ç¡®ä¿æ•°æ®å……è¶³
    let additional_buffer = if requested_days >= 200 { 
        60  // ç”¨æˆ·å·²æœ‰ç¼“å†²ï¼Œå†åŠ 60å¤©
    } else { 
        90  // ç”¨æˆ·æ²¡æœ‰ç¼“å†²ï¼ŒåŠ 90å¤©
    };
    
    let extended_start_date = user_start_date - chrono::Duration::days(additional_buffer);
    
    // ç¡®ä¿ä¸ä¼šæŸ¥è¯¢è¿‡äºä¹…è¿œçš„æ•°æ®ï¼ˆæœ€å¤š2å¹´ï¼‰
    let max_start_date = end_date - chrono::Duration::days(730);
    let actual_start_date = if extended_start_date < max_start_date {
        max_start_date
    } else {
        extended_start_date
    };
    
    let start_date_str = actual_start_date.format("%Y-%m-%d").to_string();
    let end_date_str = user_end_date.format("%Y-%m-%d").to_string();
    
    println!("ğŸ“… Aè‚¡æ•°æ®è·å–ç­–ç•¥:");
    println!("   ç”¨æˆ·è¯·æ±‚èŒƒå›´: {} åˆ° {} ({} å¤©)", 
             user_start_date.format("%Y-%m-%d"), 
             user_end_date.format("%Y-%m-%d"), 
             requested_days);
    println!("   å®é™…æŸ¥è¯¢èŒƒå›´: {} åˆ° {} ({} å¤©ï¼Œå«èŠ‚å‡æ—¥ç¼“å†²)", 
             start_date_str, end_date_str, 
             (user_end_date - actual_start_date).num_days());
    
    // ä½¿ç”¨sqlxæŸ¥è¯¢æ•°æ®åº“è·å–å†å²æ•°æ®
    let historical_data = match get_historical_data_from_db(symbol, &start_date_str, &end_date_str).await {
        Ok(data) => data,
        Err(e) => {
            eprintln!("ä»æ•°æ®åº“è·å–æ•°æ®å¤±è´¥: {e}");
            return Err(candle_core::Error::Msg(format!("è·å–å†å²æ•°æ®å¤±è´¥: {e}")));
        }
    };
    
    if historical_data.is_empty() {
        return Err(candle_core::Error::Msg("å†å²æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹".to_string()));
    }
    
    println!("âœ… è·å–åˆ°{}æ¡å†å²æ•°æ®", historical_data.len());
    
    // æ•°æ®è´¨é‡æ£€æŸ¥ - é’ˆå¯¹Aè‚¡ç‰¹ç‚¹ä¼˜åŒ–
    let valid_data: Vec<_> = historical_data.into_iter()
        .filter(|data| {
            // Aè‚¡åŸºæœ¬æ•°æ®éªŒè¯
            data.close > 0.0 && data.volume >= 0 && 
            data.open > 0.0 && data.high > 0.0 && data.low > 0.0 &&
            data.high >= data.low && data.high >= data.open && 
            data.high >= data.close && data.low <= data.open && data.low <= data.close &&
            // Aè‚¡æ¶¨è·Œå¹…é™åˆ¶æ£€æŸ¥ï¼ˆSTè‚¡ç¥¨20%ï¼Œæ™®é€šè‚¡ç¥¨10%ï¼‰
            data.change_percent.abs() <= 25.0 && // å…è®¸ä¸€äº›æ•°æ®è¯¯å·®
            // æˆäº¤é‡åˆç†æ€§æ£€æŸ¥
            data.volume < 1_000_000_000_000 // é¿å…å¼‚å¸¸å¤§çš„æˆäº¤é‡
        })
        .collect();
    
    println!("âœ… è¿‡æ»¤åæœ‰æ•ˆæ•°æ®{}æ¡", valid_data.len());
    
    // Aè‚¡äº¤æ˜“æ—¥æ•°é‡ä¼°ç®—ï¼šä¸€å¹´çº¦250ä¸ªäº¤æ˜“æ—¥
    let min_required_days = 120; // æœ€å°‘çº¦åŠå¹´äº¤æ˜“æ•°æ®
    let recommended_days = 180; // æ¨èçº¦9ä¸ªæœˆäº¤æ˜“æ•°æ®
    let optimal_days = 250; // æœ€ä½³çº¦1å¹´äº¤æ˜“æ•°æ®
    
    if valid_data.len() < min_required_days {
        return Err(candle_core::Error::Msg(format!(
            "Aè‚¡æœ‰æ•ˆäº¤æ˜“æ•°æ®ä¸è¶³ï¼Œå½“å‰{}å¤©ï¼Œéœ€è¦è‡³å°‘{}å¤©æ•°æ®ï¼ˆçº¦åŠå¹´äº¤æ˜“æ—¥ï¼‰", 
            valid_data.len(), min_required_days
        )));
    }
    
    if valid_data.len() < recommended_days {
        println!("âš ï¸  è­¦å‘Š: å½“å‰æ•°æ®é‡{}å¤©å°‘äºæ¨èçš„{}å¤©ï¼Œå¯èƒ½å½±å“æ¨¡å‹å‡†ç¡®ç‡", 
                 valid_data.len(), recommended_days);
    } else if valid_data.len() >= optimal_days {
        println!("âœ… æ•°æ®é‡å……è¶³: {}å¤© >= {}å¤©ï¼Œæœ‰åˆ©äºæé«˜æ¨¡å‹å‡†ç¡®ç‡", 
                 valid_data.len(), optimal_days);
    }
    
    // æ„å»ºç‰¹å¾å’Œæ ‡ç­¾
    let mut dates = Vec::new();
    let mut prices = Vec::new();
    let mut volumes = Vec::new();
    let mut highs = Vec::new();
    let mut lows = Vec::new();
    let mut opens = Vec::new();
    let mut features_matrix = Vec::new();
    
    // æŒ‰æ—¥æœŸæ’åºï¼ˆä»æ—§åˆ°æ–°ï¼‰
    let mut sorted_data = valid_data.clone();
    sorted_data.sort_by(|a, b| a.date.cmp(&b.date));
    
    // é¦–å…ˆæå–åŸºç¡€æ•°æ®
    for data in &sorted_data {
        dates.push(data.date.clone());
        prices.push(data.close);
        volumes.push(data.volume);
        highs.push(data.high);
        lows.push(data.low);
        opens.push(data.open);
    }
    
    // æ•°æ®å¹³æ»‘å¤„ç†ï¼šç§»é™¤å¼‚å¸¸å€¼
    let prices = smooth_price_data(&prices);
    let volumes = smooth_volume_data(&volumes);
    
    // ä¸ºæ¯å¤©å‡†å¤‡ä¸€ä¸ªç‰¹å¾å‘é‡ï¼ˆåŠ¨æ€è®¡ç®—æ‰€éœ€çš„å†å²çª—å£ï¼‰
    let required_days = request.features.iter()
        .map(|f| get_feature_required_days(f))
        .max()
        .unwrap_or(20);
    
    // ä½¿ç”¨è¾ƒå°çš„lookback_windowï¼Œä½†ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—æ‰€æœ‰ç‰¹å¾
    let lookback_window = required_days.max(30).min(prices.len() / 2);
    
    println!("ğŸ“Š ç‰¹å¾è®¡ç®—çª—å£: {}å¤©, æ€»ä»·æ ¼æ•°æ®: {}å¤©", lookback_window, prices.len());
    
    for i in lookback_window..prices.len() {
        let mut feature_vector = Vec::new();
        
        // æå–è¯·æ±‚ä¸­æŒ‡å®šçš„ç‰¹å¾
        for feature_name in &request.features {
            let feature_value = calculate_feature_value(
                feature_name, 
                &prices, 
                &volumes, 
                i, 
                lookback_window,
                Some(&highs),
                Some(&lows)
            )?;
            feature_vector.push(feature_value);
        }
        
        features_matrix.push(feature_vector);
    }
    
    println!("ğŸ”¢ ç”Ÿæˆç‰¹å¾çŸ©é˜µ: {}è¡Œ x {}åˆ—", features_matrix.len(), 
             if features_matrix.is_empty() { 0 } else { features_matrix[0].len() });
    
    // ç§»é™¤å‰é¢çš„æ•°æ®ï¼Œå› ä¸ºæ²¡æœ‰è®¡ç®—ç‰¹å¾
    dates = dates[lookback_window..].to_vec();
    let valid_prices = prices[lookback_window..].to_vec();
    
    // åˆ›å»ºç›®æ ‡å˜é‡: ä½¿ç”¨æœªæ¥nå¤©çš„ä»·æ ¼å˜åŒ–ç‡
    let pred_days = request.prediction_days;
    let mut targets = Vec::new();
    
    // é˜²æ­¢æ•´æ•°æº¢å‡ºï¼šç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œé¢„æµ‹
    if features_matrix.len() <= pred_days {
        return Err(candle_core::Error::Msg(format!(
            "æ•°æ®ä¸è¶³ä»¥è¿›è¡Œ{}å¤©é¢„æµ‹ï¼Œå½“å‰ç‰¹å¾æ•°æ®{}å¤©ï¼Œéœ€è¦è‡³å°‘{}å¤©", 
            pred_days, features_matrix.len(), pred_days + 1
        )));
    }
    
    for i in 0..(features_matrix.len() - pred_days) {
        let current_price = valid_prices[i];
        
        // è®¡ç®—æœªæ¥å‡ å¤©çš„å¹³å‡ä»·æ ¼ï¼Œå‡å°‘å™ªéŸ³
        let future_prices: Vec<f64> = (1..=pred_days)
            .map(|day| valid_prices.get(i + day).copied().unwrap_or(current_price))
            .collect();
        
        let future_avg_price = future_prices.iter().sum::<f64>() / future_prices.len() as f64;
        let change_rate = (future_avg_price - current_price) / current_price;
        
        // é™åˆ¶å˜åŒ–ç‡èŒƒå›´ï¼Œé¿å…æç«¯å€¼å½±å“è®­ç»ƒ
        let clamped_change_rate = change_rate.clamp(-0.5, 0.5);
        targets.push(clamped_change_rate);
    }
    
    // æˆªæ–­ç‰¹å¾çŸ©é˜µï¼Œä½¿å…¶ä¸ç›®æ ‡å˜é‡é•¿åº¦åŒ¹é…
    features_matrix.truncate(targets.len());
    dates.truncate(targets.len());
    
    // ç‰¹å¾æ ‡å‡†åŒ–
    let (normalized_features, _feature_stats) = normalize_features(&features_matrix)?;
    
    // åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† - ä½¿ç”¨æ—¶é—´åºåˆ—åˆ’åˆ†
    let train_size = (targets.len() as f64 * request.train_test_split) as usize;
    
    // è½¬æ¢ä¸ºå¼ é‡
    let features_len = normalized_features[0].len();
    let x_train_vec: Vec<f64> = normalized_features[0..train_size].iter()
        .flat_map(|v| v.iter().copied())
        .collect();
    
    let y_train_vec: Vec<f64> = targets[0..train_size].to_vec();
    
    let x_test_vec: Vec<f64> = normalized_features[train_size..].iter()
        .flat_map(|v| v.iter().copied())
        .collect();
    
    let y_test_vec: Vec<f64> = targets[train_size..].to_vec();
    
    // åˆ›å»ºå¼ é‡ï¼Œä½¿ç”¨F32ç±»å‹ä»¥åŒ¹é…æ¨¡å‹æƒé‡
    let x_train_f32: Vec<f32> = x_train_vec.iter().map(|&x| x as f32).collect();
    let y_train_f32: Vec<f32> = y_train_vec.iter().map(|&y| y as f32).collect();
    let x_test_f32: Vec<f32> = x_test_vec.iter().map(|&x| x as f32).collect();
    let y_test_f32: Vec<f32> = y_test_vec.iter().map(|&y| y as f32).collect();
    
    let x_train = Tensor::from_slice(&x_train_f32, &[train_size, features_len], &device)?;
    let y_train = Tensor::from_slice(&y_train_f32, &[train_size, 1], &device)?;
    
    let test_size = targets.len() - train_size;
    let x_test = Tensor::from_slice(&x_test_f32, &[test_size, features_len], &device)?;
    let y_test = Tensor::from_slice(&y_test_f32, &[test_size, 1], &device)?;
    
    println!("æ•°æ®é¢„å¤„ç†å®Œæˆ: è®­ç»ƒé›†{train_size}æ ·æœ¬, æµ‹è¯•é›†{test_size}æ ·æœ¬, ç‰¹å¾ç»´åº¦{features_len}");
    
    Ok((x_train, y_train, x_test, y_test, dates))
}

// ç‰¹å¾æ ‡å‡†åŒ–
fn normalize_features(features: &[Vec<f64>]) -> Result<(Vec<Vec<f64>>, Vec<(f64, f64)>), candle_core::Error> {
    if features.is_empty() {
        return Ok((Vec::new(), Vec::new()));
    }
    
    let feature_count = features[0].len();
    let mut stats = Vec::with_capacity(feature_count);
    let mut normalized = vec![vec![0.0; feature_count]; features.len()];
    
    // è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å‡å€¼å’Œæ ‡å‡†å·®
    for feature_idx in 0..feature_count {
        let values: Vec<f64> = features.iter().map(|row| row[feature_idx]).collect();
        let mean = values.iter().sum::<f64>() / values.len() as f64;
        let variance = values.iter()
            .map(|v| (v - mean).powi(2))
            .sum::<f64>() / values.len() as f64;
        let std_dev = variance.sqrt().max(1e-8); // é¿å…é™¤é›¶
        
        stats.push((mean, std_dev));
        
        // æ ‡å‡†åŒ–è¯¥ç‰¹å¾
        for (row_idx, row) in features.iter().enumerate() {
            normalized[row_idx][feature_idx] = (row[feature_idx] - mean) / std_dev;
        }
    }
    
    Ok((normalized, stats))
}

// è®­ç»ƒæ¨¡å‹å‡½æ•°
pub async fn train_candle_model(request: TrainingRequest) -> std::result::Result<TrainingResult, String> {
    let model_id = generate_model_id();
    let model_type = request.model_type.clone();
    
    println!("ğŸš€ å¼€å§‹è®­ç»ƒé‡‘èçº§æ·±åº¦ç¥ç»ç½‘ç»œæ¨¡å‹...");
    
    // å‡†å¤‡æ•°æ®
    let (x_train, y_train, x_test, y_test, _) = prepare_stock_data(&request).await
        .map_err(|e| format!("æ•°æ®å‡†å¤‡å¤±è´¥: {e}"))?;
    
    // è®¾ç½®è®¾å¤‡
    let device = Device::Cpu;
    
    // åˆ›å»ºæ¨¡å‹é…ç½® - é‡‘èçº§å‚æ•°
    let config = ModelConfig {
        model_type: model_type.clone(),
        input_size: request.features.len(),
        hidden_size: 128, // å¢å¤§éšè—å±‚ï¼š64 -> 128
        output_size: 1,
        dropout: request.dropout.max(0.2), // è‡³å°‘20% dropout
        learning_rate: request.learning_rate,
        n_layers: 3,     // 3å±‚ç½‘ç»œ
        n_heads: 4,
        max_seq_len: 60,
    };
    
    println!("ğŸ“ æ¨¡å‹æ¶æ„:");
    println!("   è¾“å…¥ç»´åº¦: {}", config.input_size);
    println!("   éšè—å±‚: {} (ç¬¬1å±‚: {}, ç¬¬2å±‚: {}, ç¬¬3å±‚: {}, ç¬¬4å±‚: {})", 
             config.hidden_size, 
             config.hidden_size * 2,
             config.hidden_size,
             config.hidden_size / 2,
             config.hidden_size / 4);
    println!("   è¾“å‡ºç»´åº¦: {}", config.output_size);
    println!("   Dropoutç‡: {:.1}%", config.dropout * 100.0);
    
    // åˆ›å»ºæ¨¡å‹
    let (varmap, model) = create_model(&config, &device)
        .map_err(|e| format!("æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}"))?;
    
    // åˆ›å»ºä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨AdamWï¼Œæ›´é€‚åˆæ·±åº¦ç½‘ç»œï¼‰
    let initial_lr = request.learning_rate;
    let mut optimizer = AdamW::new_lr(varmap.all_vars(), initial_lr)
        .map_err(|e| format!("ä¼˜åŒ–å™¨åˆ›å»ºå¤±è´¥: {e}"))?;
    
    println!("ğŸ¯ è®­ç»ƒé…ç½®:");
    println!("   åˆå§‹å­¦ä¹ ç‡: {:.6}", initial_lr);
    println!("   æ‰¹æ¬¡å¤§å°: {}", request.batch_size);
    println!("   è®­ç»ƒè½®æ•°: {}", request.epochs);
    
    // è®­ç»ƒå¾ªç¯ - å¢å¼ºç‰ˆ
    let batch_size = request.batch_size;
    let num_batches = x_train.dim(0).unwrap() / batch_size;
    
    // æ—©åœæœºåˆ¶
    let mut best_val_loss = f64::INFINITY;
    let mut patience_counter = 0;
    let patience = 15; // 15ä¸ªepochæ— æ”¹è¿›åˆ™åœæ­¢
    let min_delta = 0.0001; // æœ€å°æ”¹è¿›é˜ˆå€¼
    
    // å­¦ä¹ ç‡è¡°å‡
    let lr_decay_factor: f64 = 0.95; // æ¯æ¬¡è¡°å‡5%
    let lr_decay_epochs = 20;        // æ¯20ä¸ªepochè¡°å‡ä¸€æ¬¡
    
    println!("\nğŸ”„ å¼€å§‹è®­ç»ƒ...");
    
    for epoch in 0..request.epochs {
        let mut epoch_loss = 0.0;
        let mut batch_count = 0;
        
        // åŠ¨æ€å­¦ä¹ ç‡è°ƒæ•´
        if epoch > 0 && epoch % lr_decay_epochs == 0 {
            let new_lr = initial_lr * lr_decay_factor.powi((epoch / lr_decay_epochs) as i32);
            optimizer = AdamW::new_lr(varmap.all_vars(), new_lr)
                .map_err(|e| format!("æ›´æ–°å­¦ä¹ ç‡å¤±è´¥: {e}"))?;
            println!("ğŸ“‰ ç¬¬{}è½®: å­¦ä¹ ç‡è¡°å‡è‡³ {:.6}", epoch + 1, new_lr);
        }
        
        // è®­ç»ƒé˜¶æ®µ
        for batch_idx in 0..num_batches {
            let batch_start = batch_idx * batch_size;
            let x_batch = x_train.narrow(0, batch_start, batch_size)
                .map_err(|e| format!("æ‰¹æ¬¡æ•°æ®å‡†å¤‡å¤±è´¥: {e}"))?;
            let y_batch = y_train.narrow(0, batch_start, batch_size)
                .map_err(|e| format!("æ‰¹æ¬¡æ ‡ç­¾å‡†å¤‡å¤±è´¥: {e}"))?;
            
            // å‰å‘ä¼ æ’­
            let output = model.forward(&x_batch)
                .map_err(|e| format!("å‰å‘ä¼ æ’­å¤±è´¥: {e}"))?;
            
            // å½¢çŠ¶åŒ¹é…
            let reshaped_output = if output.dims() != y_batch.dims() {
                if output.dim(0).unwrap() == y_batch.dim(0).unwrap() {
                    output.reshape(&[output.dim(0).unwrap(), 1])
                        .map_err(|e| format!("è°ƒæ•´è¾“å‡ºå½¢çŠ¶å¤±è´¥: {e}"))?
                } else {
                    return Err(format!("å½¢çŠ¶ä¸å…¼å®¹: {:?} vs {:?}", output.dims(), y_batch.dims()));
                }
            } else {
                output
            };
            
            // è®¡ç®—æŸå¤± (MSE + L2æ­£åˆ™åŒ–)
            let diff = reshaped_output.sub(&y_batch)
                .map_err(|e| format!("è®¡ç®—å·®å€¼å¤±è´¥: {e}"))?;
            let mse_loss = diff.sqr()
                .map_err(|e| format!("è®¡ç®—å¹³æ–¹å¤±è´¥: {e}"))?
                .mean_all()
                .map_err(|e| format!("è®¡ç®—å‡å€¼å¤±è´¥: {e}"))?;
            
            // L2æ­£åˆ™åŒ–ï¼ˆæƒé‡è¡°å‡ï¼‰
            let l2_lambda = 0.0001;
            let mut l2_loss = 0.0;
            for var in varmap.all_vars() {
                let weight_norm = var.sqr()
                    .map_err(|e| format!("è®¡ç®—æƒé‡èŒƒæ•°å¤±è´¥: {e}"))?
                    .sum_all()
                    .map_err(|e| format!("æ±‚å’Œå¤±è´¥: {e}"))?;
                l2_loss += weight_norm.to_scalar::<f32>().unwrap() as f64;
            }
            
            let total_loss = mse_loss.to_scalar::<f32>().unwrap() as f64 + l2_lambda * l2_loss;
            
            // åå‘ä¼ æ’­
            optimizer.backward_step(&mse_loss)
                .map_err(|e| format!("åå‘ä¼ æ’­å¤±è´¥: {e}"))?;
            
            epoch_loss += total_loss;
            batch_count += 1;
        }
        
        let avg_train_loss = epoch_loss / batch_count as f64;
        
        // éªŒè¯é˜¶æ®µï¼ˆä½¿ç”¨æµ‹è¯•é›†è¯„ä¼°ï¼‰
        let val_output = model.forward(&x_test)
            .map_err(|e| format!("éªŒè¯å‰å‘ä¼ æ’­å¤±è´¥: {e}"))?;
        let reshaped_val_output = if val_output.dims() != y_test.dims() {
            val_output.reshape(&[y_test.dim(0).unwrap(), 1])
                .map_err(|e| format!("éªŒè¯è¾“å‡ºå½¢çŠ¶è°ƒæ•´å¤±è´¥: {e}"))?
        } else {
            val_output
        };
        let val_diff = reshaped_val_output.sub(&y_test)
            .map_err(|e| format!("éªŒè¯å·®å€¼è®¡ç®—å¤±è´¥: {e}"))?;
        let val_loss = val_diff.sqr()
            .map_err(|e| format!("éªŒè¯å¹³æ–¹å¤±è´¥: {e}"))?
            .mean_all()
            .map_err(|e| format!("éªŒè¯å‡å€¼å¤±è´¥: {e}"))?
            .to_scalar::<f32>().unwrap() as f64;
        
        // æ—©åœåˆ¤æ–­
        if val_loss < best_val_loss - min_delta {
            best_val_loss = val_loss;
            patience_counter = 0;
        } else {
            patience_counter += 1;
        }
        
        // æ—¥å¿—è¾“å‡º
        if epoch == 0 || (epoch + 1) % 5 == 0 || epoch == request.epochs - 1 || patience_counter >= patience {
            println!("Epoch {:3}/{} | è®­ç»ƒLoss: {:.6} | éªŒè¯Loss: {:.6} | æœ€ä½³Loss: {:.6} | è€å¿ƒ: {}/{}",
                     epoch + 1, 
                     request.epochs, 
                     avg_train_loss, 
                     val_loss, 
                     best_val_loss,
                     patience_counter,
                     patience);
        }
        
        // æ—©åœè§¦å‘
        if patience_counter >= patience {
            println!("â¹ï¸  æ—©åœè§¦å‘ï¼{}ä¸ªepochæœªæ”¹è¿›ï¼Œåœæ­¢è®­ç»ƒ", patience);
            println!("ğŸ“Š æœ€ä½³éªŒè¯Loss: {:.6}", best_val_loss);
            break;
        }
    }
    
    println!("âœ… è®­ç»ƒå®Œæˆï¼");
    
    // è¯„ä¼°æ¨¡å‹
    let y_pred = model.forward(&x_test)
        .map_err(|e| format!("é¢„æµ‹å¤±è´¥: {e}"))?;
    
    // è½¬æ¢ä¸ºVecç”¨äºå‡†ç¡®ç‡è®¡ç®— - å¤„ç†ä¸åŒç»´åº¦çš„å¼ é‡
    let predictions_vec = match y_pred.dims() {
        // å¦‚æœæ˜¯1ç»´å¼ é‡ [n]
        [_] => {
            y_pred.to_vec1::<f32>().map_err(|e| format!("è½¬æ¢1ç»´é¢„æµ‹ç»“æœå¤±è´¥: {e}"))?
                .into_iter().map(|x| x as f64).collect::<Vec<f64>>()
        },
        // å¦‚æœæ˜¯2ç»´å¼ é‡ [n, 1] 
        [_, 1] => {
            y_pred.to_vec2::<f32>().map_err(|e| format!("è½¬æ¢2ç»´é¢„æµ‹ç»“æœå¤±è´¥: {e}"))?
                .into_iter().map(|row| row[0] as f64).collect::<Vec<f64>>()
        },
        // å¦‚æœæ˜¯å…¶ä»–2ç»´å¼ é‡ [n, m]
        [_, _] => {
            let vec2d = y_pred.to_vec2::<f32>().map_err(|e| format!("è½¬æ¢2ç»´é¢„æµ‹ç»“æœå¤±è´¥: {e}"))?;
            vec2d.into_iter().map(|row| row[0] as f64).collect::<Vec<f64>>() // å–ç¬¬ä¸€åˆ—
        },
        // å…¶ä»–ç»´åº¦
        _ => {
            return Err("é¢„æµ‹è¾“å‡ºå¼ é‡ç»´åº¦ä¸æ”¯æŒï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®".to_string());
        }
    };
    
    let actuals_vec = match y_test.dims() {
        // å¦‚æœæ˜¯1ç»´å¼ é‡ [n]
        [_] => {
            y_test.to_vec1::<f32>().map_err(|e| format!("è½¬æ¢1ç»´å®é™…ç»“æœå¤±è´¥: {e}"))?
                .into_iter().map(|x| x as f64).collect::<Vec<f64>>()
        },
        // å¦‚æœæ˜¯2ç»´å¼ é‡ [n, 1]
        [_, 1] => {
            y_test.to_vec2::<f32>().map_err(|e| format!("è½¬æ¢2ç»´å®é™…ç»“æœå¤±è´¥: {e}"))?
                .into_iter().map(|row| row[0] as f64).collect::<Vec<f64>>()
        },
        // å¦‚æœæ˜¯å…¶ä»–2ç»´å¼ é‡ [n, m]
        [_, _] => {
            let vec2d = y_test.to_vec2::<f32>().map_err(|e| format!("è½¬æ¢2ç»´å®é™…ç»“æœå¤±è´¥: {e}"))?;
            vec2d.into_iter().map(|row| row[0] as f64).collect::<Vec<f64>>() // å–ç¬¬ä¸€åˆ—
        },
        // å…¶ä»–ç»´åº¦
        _ => {
            return Err("å®é™…å€¼å¼ é‡ç»´åº¦ä¸æ”¯æŒï¼Œè¯·æ£€æŸ¥æ•°æ®å‡†å¤‡".to_string());
        }
    };
    
    // ä½¿ç”¨æ”¹è¿›çš„å‡†ç¡®ç‡è®¡ç®—æ–¹æ³•ï¼ˆæ›´é‡è§†æ–¹å‘é¢„æµ‹ï¼‰
    let (direction_accuracy, combined_accuracy) = calculate_direction_focused_accuracy(&predictions_vec, &actuals_vec);
    
    // è®¡ç®—MSEå’ŒRMSEç”¨äºæ—¥å¿—æ˜¾ç¤º
    let diff = y_pred.sub(&y_test).map_err(|e| format!("è®¡ç®—MSEå¤±è´¥: {e}"))?;
    let squared_diff = diff.sqr().map_err(|e| format!("è®¡ç®—å¹³æ–¹å¤±è´¥: {e}"))?;
    let mse = squared_diff.mean_all().map_err(|e| format!("è®¡ç®—å‡å€¼å¤±è´¥: {e}"))?;
    let mse = mse.to_scalar::<f32>().unwrap() as f64;
    let rmse = mse.sqrt();
    
    println!("è¯„ä¼°ç»“æœ: MSE = {mse:.4}, RMSE = {rmse:.4}");
    println!("ğŸ¯ æ–¹å‘é¢„æµ‹å‡†ç¡®ç‡: {:.2}% | ç»¼åˆå‡†ç¡®ç‡: {:.2}%", 
             direction_accuracy * 100.0, combined_accuracy * 100.0);
    println!("ğŸ“Š é¢„æµ‹å¼ é‡ç»´åº¦: {:?}, å®é™…å¼ é‡ç»´åº¦: {:?}", y_pred.dims(), y_test.dims());
    
    // ä¿å­˜æ¨¡å‹
    let model_path = get_model_file_path(&model_id);
    fs::create_dir_all(model_path.parent().unwrap()).map_err(|e| format!("åˆ›å»ºæ¨¡å‹ç›®å½•å¤±è´¥: {e}"))?;
    save_model(&varmap, &model_path).map_err(|e| format!("æ¨¡å‹ä¿å­˜å¤±è´¥: {e}"))?;
    
    // ä¿å­˜æ¨¡å‹å…ƒæ•°æ®
    let metadata = ModelInfo {
        id: model_id,
        name: request.model_name,
        stock_code: request.stock_code,
        created_at: get_current_timestamp(),
        model_type,
        features: request.features,
        target: request.target,
        prediction_days: request.prediction_days,
        accuracy: combined_accuracy,
    };
    
    save_model_metadata(&metadata).map_err(|e| format!("å…ƒæ•°æ®ä¿å­˜å¤±è´¥: {e}"))?;
    
    Ok(TrainingResult {
        metadata,
        accuracy: combined_accuracy,
    })
} 